# 操作系统导论

> [!TIP]
>
> 本文将从 虚拟化（virtulization）、并发（concurrency）、持久性（persistence）这部分介绍操作系统是如何进行工作的，包括如何决定接下来哪个程序使用cpu，如何在虚拟内存系统中处理内存使用过载，虚拟机监控器如何工作，如何处理磁盘上的数据等等。

操作系统三个设计目标

1. 建立抽象，方便程序使用
2. 提供高性能
3. 在应用程序之间以及os和应用之间提供保护

## 虚拟化

什么是虚拟化，操作系统可以认为是一个通用的计算机软件，它向其他更接近用户层的应用程序提供了许多通用的接口，操作系统允许程序共享内存、允许程序与设备进行交互等等，不同的程序对计算机资源的使用要求可能是不同的，因此我们希望对于不同需求的应用程序所能看到的资源都是一样的形式，这也算是一种透明，虚拟化就是做了一件这样的事：它让物理资源（处理器、内存、磁盘等）转换为更加通用、更强大且更容易使用的虚拟形式。无非虚拟化cpu就是让每个应用程序都认为自己是独占cpu的，虚拟化内存让每个程序都认为自己是独占内存空间的，程序与程序之间不知道对方的存在。

### 虚拟化cpu

在讲虚拟化cpu之前，我们首先要介绍一个对于前文提到的“应用程序”的一种抽象：进程。

#### 进程

进程是操作系统提供的最基本的抽象，进程的定义也非常的简单：<u>进程就是运行中的程序。</u>程序本身是没有生命周期的，本质上是一些指令，是操作系统让程序运行起来从而发挥作用的。

> [!NOTE]
>
> 一个非常常见的需求：多个程序需要同时运行，但是计算机刚发展时是单cpu的，操作系统如何实现每个程序都能“同时”使用到cpu，从而实现我们的需求？

事实上实现这件事也就是实现了虚拟化cpu。

通过让一个进程只运行一小段时间（我们称这一小段时间为一个*时间片*），然后切换到其他进程，这样操作系统也就提供了存在多个cpu的假象。这就是时分共享（time sharing）cpu技术。

辩证的看待这个方案，潜在的问题就是效率降低，因为cpu共享进程就要切换，就会有上下文切换的额外性能损失。

如何高效进行cpu共享，这就需要用到操作系统的一些低阶的机制以及一些高阶的智能。所谓的机制就是”怎么切换进程”，需要配合硬件等实现上下文切换之类的事情；而策略就是“切换哪些进程”，涉及到一些算法，什么时候切换哪些进程。

为了实现我们的终极目标，我们还需要搞清楚：到底什么是进程？

##### 究竟什么是进程？进程需要包含哪些信息？

重申一下：进程就是操作系统对正在运行的程序提供的抽象。进程就是一个正在运行的程序，任何时候，只要我们知道了一个进程访问或者影响了系统的哪些部分，我们也就知道了进程具体是什么了。

为了进一步理解究竟什么是进程，我们就需要理解它每时每刻能影响系统的哪些状态，我们称这些状态为机器状态（machine state）：程序在运行时可以更新或者读取的内容。

所谓进程的机器状态有一个最明显也是最重要的组成部分：<u>内存</u>。程序的指令存在内存中，进程要读写的数据也在内存中，所以进程可以访问的内存也是进程的一部分（很显然，不是吗）

> [!TIP]
>
> 进程能访问的内存也称为地址空间（address space）这部分将在虚拟化内存中详细介绍。

进程的机器状态另一部分就是<u>寄存器</u>。寄存器是一种比所谓的缓存更加高速的缓存硬件。很多时候为了提升计算效率，寄存器也是进程频繁操作的目标，因此也属于进程的一部分。

特别的，有些特殊的寄存器可以认为是每个进程的必需品，比如程序计数器（Program Counter PC有时叫做指令指针，Instruction Pointer IP），栈指针、帧指针等管理函数参数、局部变量和返回地址等，这些也属于进程的一部分。

##### 进程创建要做的一些事情

操作系统创建进程必须要做的第一件事就是将代码和所有静态数据加载到内存中，也就是加载到内存的地址空间中。当然现代操作系统都是惰性加载的，即仅在程序执行期间需要加载某些代码或者数据时才会加载，具体的细节在将来的分页和交换机制中会了解到。（本质上就是只存一个在磁盘中的位置，需要的时候再从磁盘加载，当然存储的信息不只有磁盘位置这么点）

将（必要的）代码和静态数据加载到内存后，操作系统还需要为程序运行时栈分配一些内存，这个栈用来存储程序中的局部变量、函数参数和返回地址中（以c语言为例）。有时操作系统可能会初始化栈中的某些信息，比如main函数的参数列表等。

除了为栈分配内存，还可能会为程序的堆分配内存。C程序中使用malloc显式的为程序分配堆空间。

还有一些其他的初始任务，特别是与I/O相关的任务。比如在UNIX系统，默认情况下每个进程都会有三个打开的文件描述符，用于进行标准的输入、输出和错误。这些描述符可以让程序轻松的读取来自终端的输入以及打印输出到屏幕。关于这部分将在持久化中详细了解。

至此，操作系统终于为程序执行搭建了所有需要的内容，然后最后一件事情就是：启动程序。通过将程序跳转到main函数位置，将cpu控制权交给新创建的进程，从而程序开始执行。

##### 进程有哪些状态

不同的时间进程可能会有不同的表现，这也是为了达到某些目的而使用的一种手段，我们称为进程的状态

- 运行（running）：进程正在处理上运行。
- 就绪（ready）：进程已经准备上执行，但是由于某种原因，操作系统并没有选择在此时执行。
- 阻塞（blocked）：当前进程由于执行了某种操作（比如io操作）而处于的一种状态，直到发生其他事件时才会准备运行。

![进程状态](https://gitee.com/raining976/markdown-imgs/raw/master/img/image-20241001195028550.png)

从就绪到运行意味着该进程已经被调度；从运行到就绪意味着该进程已经取消调度。

一旦进程被阻塞，OS将保持进程的这种状态，直到发生某种事件（比如io完成），此时进程再次转入就绪状态（也可能直接执行，这由操作系统决定）

##### 如何跟踪进程

真实的操作系统中的关于进程跟踪的数据结构往往特别复杂，首先必要的结构是寄存器上下文，进程在切换时，所依赖的各种寄存器的值需要被保存，保存到哪里？保存到进程所在的内存位置，通过恢复寄存器（将内存中的这些值重新赋值回实际的物理寄存器中）。这个保存又恢复（恢复另一个）的过程也称为上下文切换（context switch）

保存寄存器上下文的数据结构可能长这个样：

```c
struct context {
       int eip;
       int esp;
       int ebx;
       int ecx;
       int edx;
       int esi;
       int edi;
       int ebp;
};
```

除此之外，还有进程本身的一些内容也需要跟踪，可能是这样的结构：

```c

// the different states a process can be in
enum proc_state { UNUSED, EMBRYO, SLEEPING,
               RUNNABLE, RUNNING, ZOMBIE };
// the information xv6 tracks about each process
// including its register context and state
struct proc {
  char *mem;							// 当前进程的开始内存
  uint sz;						  	// 进程空间大小
  char *kstack;						// 该进程的内核栈底
  enum proc_state state;	// 进程状态
  int pid;								// 进程id
  struct proc *parent;		// 父进程
  void *chan;							// If non-zero, sleeping on chan
  int killed;							// 不为0表示当前进程已被杀死
  struct file *ofile[NOFILE];  // 打开的文件
  struct inode *cwd;		 	// 当前目录
  struct context context;	// 上下文
  struct trapframe *tf;		// Trap frame for the current interrupt
};
```

有时候人们会将存储关于进程的信息的个体结构称为进程控制块（Process Control Block， PCB），这是谈论包含每个进程信息的c结构的一种方式。

#### 进程调用api（无关紧要的内容）

> [!note]
>
> 实践相关的内容

##### fork()

fork会生成一份与原来一模一样的代码，但是执行位置是从fork调用的位置执行，区分父进程和子进程的方式是通过fork返回的进程id，对于子进程来讲，返回的进程id就是0；对于父进程，返回的进程id就是一个比较大的整数，也就是子进程的进程id。

注意父子进程的执行顺序并不固定，这取决于操作系统如何进行调用。

fork父子进程共用同一份代码，现代操作系统实现时实际也是这么干的！在执行fork时并没有直接真正的拷贝一份内存空间到子进程，而是将子进程的虚拟内存（我们将在之后详细介绍这个概念）指向了与父进程一样的同一块物理内存，同时这两个进程对这部分内存的权限都是只读。这样只要父子进程不修改，看起来好像就是拷贝了一份似的！如果进程此时修改，那么会陷入操作系统，操作系统执行对应的陷阱程序，分配新的物理内存，也就是说，写的时候才进行拷贝，因此这种策略也称为*写时复制*。

##### wait()

可以控制父子进程之间的调用顺序，父进程调用wait()，就会延迟自己的执行，直到子进程执行完毕，wait()才会返回父进程。

##### exec()

exec是创建进程api的一个重要部分。该系统调用配合fork()可以让子进程执行与父进程不一样的程序。

exec传入执行的程序以及程序的参数列表，此时exec会从可执行程序中加载代码和静态数据，并用它覆写自己的代码段以及静态数据，堆、栈等其他内存空间也会被重新初始化。然后操作系统执行该程序。

实际上，它并没有创建新的程序，而是直接将当前运行的程序直接替换为了指定的那个程序，子进程执行exec后，就像从来没有执行过原来的程序一样，堆exec的调用也永远不会返回。

##### 为什么设计如此奇怪的api？

看起来很奇怪，实际上fork和exec分离的设计在构建UNIX shell的时候非常有用，因为这给了shell在fork之后exec之前运行代码的机会，这些代码可以在运行新的程序前改变环境，从而让一些看起来复杂的功能实现起来非常容易。

比如shell中的重定向命令：`>`

shell中实现非常容易，在完成子进程的创建之后，调用exec之前先关闭标准输出，然后打开输出的目标文件。这样运行的程序就会将结果发送到目标文件中了。

之所以可以这样顺理成章的被透明的写入目标文件而不是打印到屏幕，是基于对操作系统管理文件描述符的假设。具体来说，UNIX系统会从0开始寻找可以 使用的文件描述符，打开文件就意味着STDOUT_FILENO会成为第一个可用的文件描述符，因此子进程在对标准输出文件描述符写入时，写入的内容都会被透明的传输到新打开的文件。

实际上，UNIX管道符也是用类似的方式实现的，不过用的是pipe()系统调用。

#### 机制：受限直接执行

为了虚拟化cpu，也就是操作系统需要以一种方式让多个任务共享cpu，让它们看起来是同时运行的。基本的思想很简单：每个进程交替执行一段时间，这种方式称为*时分共享*

##### 两个问题

1. 性能问题：在不增加操作系统开销的情况下实现虚拟CPU。
2. 控制权问题：如何既共享cpu，又能保证cpu的控制权。

尤其是控制权，如果一个进程无限掌握cpu，那可能会造成无法预料的后果，这也是操作系统不愿意看到的。

> [!tip]
>
> 如何高效、可控的虚拟化CPU

##### 核心思路：受限直接执行

直接执行的含义很简单，就是让进程直接在cpu执行即可。

在没有限制的情况下，我们很容易想到，若操作系统想要启动某个程序，首先在进程列表里创建一个进程条目，为其分配内存，将代码加载到内存中，然后找到main函数入口，跳转到那里，并开始运行用户代码。此时也就完成了cpu控制权的转移。

接下来，按照我们预想的结果，用户程序顺利执行完代码，然后跳转回操作系统之前的位置，控制权换回来了。

可事实真的总是如我们想的这样吗？设想这样一种情况：用户代码进入了死循环。此时操作系统就永远无法获得cpu控制权了，这很糟糕。不仅如此，我们怎么保证程序不做操作系统不希望它做的事情？

因此进一步抛出两个问题：

1. 如果我们只运行一个程序，如何保证它不做我们不希望它做的事，同时高效运行它。
2. 当我们运行一个进程的时候，操作系统如何让它停下来并切换另一个进程。

##### 解决问题1:受限制的操作

为了解决问题1，我们让进程不能随便执行命令，而是限制它执行某些命令。

> [!note] 受保护的控制权转移
>
> 需要硬件与操作系统协作。也就是所谓的特权级架构：用户模式、内核模式。
>
> 用户模式下不能完全访问硬件资源，内核模式下操作系统可以访问机器的全部资源。
>
> 这种架构下提供了一种trap命令，用来从用户模式陷入到内核模式，让操作系合法的做“用户程序想要做却不能做的事”。包括返回陷阱指令，返回到用户模式。

用户程序如果想要执行某种特权操作，应该怎么做？几乎所有的现代硬件都提供给用户程序执行系统调用的能力，我们称之为*系统调用*。但是要执行系统调用，用户程序必须要陷入内核，将特权提升到内核模式，此时又操作系统为用户程序执行它想要执行的特权操作，执行完成通过陷阱返回指令返回到用户程序，同时特权级别降到用户级别。

还有一个比较关键的问题：就是在程序陷入时，陷阱如何知道要在OS内运行哪些代码？

显然这不能让程序指定，程序是不被信任的。操作系统通过在系统时设置*陷阱表*来实现，陷阱表就是告诉硬件在发生某些异常时，要运行哪些代码。

下表总结了受限直接运行协议：

| 操作系统@启动（内核模式）                                    | 硬件                                                         |                                    |
| :----------------------------------------------------------- | ------------------------------------------------------------ | ---------------------------------- |
| 初始化陷阱表                                                 |                                                              |                                    |
|                                                              | 记住系统调用处理程序的地址                                   |                                    |
| 操作系统@运行（内核模式）                                    | 硬件                                                         | 应用程序                           |
| 在进程列表创建条目<br />为程序分配内存<br />将程序加载到内存<br />根据argv设置程序栈<br />用寄存器/程序计数器填充内核栈<br />从陷阱返回 |                                                              |                                    |
|                                                              | 从内核栈恢复寄存器<br />转向用户模式<br />跳到main           |                                    |
|                                                              |                                                              | 运行main<br />……<br />             |
|                                                              |                                                              | 调用系统调用<br />陷入操作系统     |
|                                                              | 将寄存器保存到内核栈<br />转向内核模式<br />跳到陷阱处理程序 |                                    |
| 处理陷阱<br />做系统调用的工作<br />从陷阱返回               |                                                              |                                    |
|                                                              | 从内核栈恢复寄存器<br />转向用户模式<br />跳到陷阱之后的程序计数器 |                                    |
|                                                              |                                                              | 从main返回<br />陷入（通过exit()） |
| 释放进程的内存<br />将进程从进程列表中清除                   |                                                              |                                    |

我们可以看到，LDE协议有两个阶段。

1. 系统引导阶段：内核初始化陷阱表，并且硬件记住它们的位置以供将来使用
2. 运行进程阶段：在使用从陷阱返回指令执行进程之前，内核先设置了一些有关于进程的内容，然后切换到用户模式，开始执行进程。当进程希望发出系统调用时，会重新陷入操作系统，然后再次通过从陷阱返回，将控制权还给进程。直到进程完成所有的main代码，通过exit系统调用，陷入os，os清理该进程相关内容，进程到此也全部完成并正常退出了。

##### 解决问题2:在进程之间切换

> [!tip] 关键问题
>
> 操作系统如何重新获得cpu控制权？

###### 协作方式：等待系统调用

这与LDE协议中的过程类似，操作系统信任程序会在一段时间之后发起系统调用，然后cpu控制权转移给内核。显然，这种被动的方式不太合理，设想一个进程获取cpu控制权后进入了无限循环，此时操作系统将彻底失去对cpu的控制。

###### 非协作时：操作系统主动控制

最无脑的方式：重新启动计算机。开个玩笑。

关键问题就是**如何在进程不配合的情况下，操作系统还能重新拿回cpu的控制权？**

答案很简单，许多年前构建计算机系统的许多人都发现了：*时钟中断（timer interrupt）*

时钟设备可以编程为每隔几毫秒产生一次中断，产生中断时，当前运行的进程中止，操作系统中预先配置的中断处理成会运行，此时os也就重新拿回的cpu控制权，继续做它想做的事情，比如停止当前进程，启动另一个进程。

> [!important]
>
> 很容易看出来，时钟中断对帮助**操作系统维持机器的控制权**至关重要。

产生中断时，硬件也做一些事情。为正在运行的程序保存足够的状态，以便在下次继续执行进程时正确恢复。

###### 保存和恢复上下文

如果os在中断后选择停止当前进程，启动另一个进程。那么就需要为当前的正在执行的进程保存一些寄存器的值（可能保存到它的内核栈），并为即将要执行的进程恢复一些寄存器的值（从它的内核栈），这就是*上下文切换（context switch）*的概念。这样一来，操作系统执行从陷阱返回指令就不会回到原来的进程了，还是继续执行另一个进程。

下面详细介绍了时钟中断并切换进程时os和硬件要做的事情：

| 操作系统@启动（内核模式）                                    | 硬件                                                         |          |
| ------------------------------------------------------------ | ------------------------------------------------------------ | -------- |
| 初始化陷阱表                                                 |                                                              |          |
|                                                              | 记住以下地址：<br />1. 系统调用处的地址<br />2. 时钟中断处理程序 |          |
| 启动中断时钟                                                 |                                                              |          |
|                                                              | 启动时钟<br />每隔x ms中断CPU                                |          |
| 操作系统@运行（内核模式）                                    | 硬件                                                         | 程序     |
|                                                              |                                                              | 进程A... |
|                                                              | 时钟中断<br />将寄存器（A）保存到内核栈（A）<br />转向内核模式<br />跳到陷阱处理程序 |          |
| 处理陷阱<br />调用switch()切换进程<br />将寄存器（A）保存到进程结构（A）<br />将进程结构（B）恢复到寄存器（B）<br />从陷阱返回（这时就会进入B） |                                                              |          |
|                                                              | 从内核栈（B）恢复寄存器（B）<br />转向用户模式<br />跳到B的程序计数器 |          |
|                                                              |                                                              | 进程B... |

注意这个过程有两种类型的寄存器保存/恢复：

1. 时钟中断时，将当前进程用到的寄存器保存在该**进程的内核栈**
2. 操作系统选择切换进程时，将原来的进程用到的寄存器值保存到**该进程的进程结构中**

> [!tip] 重新启动是有用的！
>
> 我们之前提到过，在协作式抢占时，无限循环的唯一解决方案就是reboot。虽然这看起来是个玩笑，但是研究表明，重启（或者通常意义上，重新开始运行一些软件）可能是构建强大系统非常有用的一个工具。
>
> 为什么这么说呢？首先重启可以让软件回到已知的状态，而这种状态往往是经过了大量的测试的状态。其次，重启可以回收旧的或者泄漏的资源，这些资源可能没有一种好的办法处理。最后，重启很容易自动化。常见的大规模集群的互联网服务中，系统管理软件会定期重启一些机器，以此来获得以上的好处。

至此，我们已经解决了如何保证os控制权以及如何进行进程切换的问题（上下文切换），接下来要解决的事情就是：进程切换时我们要运行哪个进程？这是进程调度程序必须要回答的问题，因此这是我们接下来研究的主题。

#### 进程调度

遵循我们一贯以来的想法，实现一个策略之前，我们做出一些关键的假设，以使得系统构建更加简单，未来我们会不断放宽这种假设，以使得其接近真实的世界。

##### 工作负载假设

我们对操作系统中运行的进程（有时也叫工作任务）作出如下假设

1. 每个工作运行相同的时间
2. 所有的工作同时到达
3. 一旦开始，每个工作保持运行直到完成
4. 所有的工作只是用CPU（也就是它们不执行io操作）
5. 每个工作的工作时间是已知的

这确实看起来是不现实的，但是这对我们构建一个完整健全的系统有一个很好的开始，因为一开始就罗列所有复杂的需求会让人不知道从何处着手。

##### 调度指标

什么样的调度是“好”的，我们需要给出定义这个“好”的标准。

这里为了简化我们只使用一个标准：*周转时间（turnaround time）*，这是一个性能指标。任务的周转时间指的是任务完成时间减去任务到达系统的时间。

$T_{周转时间}=T_{完成时间}-T_{到达时间}$​

我们最初的假设所有任务同时到达，因此在最严格的假设中，任务的周转时间也就是任务完成的时间。

##### 先进先出（FIFO）

最基本的一种非抢占式调度算法，有时也称为*先到先服务（First Come First，FCFS ）*。

FIFO有着最明显的优势：简单，容易实现。而且在我们最严格的假设下，它效果很好。

下面介绍一个例子来描述FIFO的调度策略。三个工作A、B、C，在大致相同的时间到达系统，因为需要明确先后顺序，于是我们就假设A比B早到一点点，B比C早到一点点。假设每个工作运行10s。这些工作的*平均周转（average turnaround time）*时间是多少？

A在10s时执行完成，B在20s时执行完成，C在30s时执行完成，因此平均周转时间为$(10+20+30)/3=20s$。这看起来还不错？

接下来我们<u>放宽假设1:每个任务的运行时间不再相同。</u>

假设A运行时间变为100s，B和C还是10s。接下来我们计算它们的平均周转时间：$(100+110+120)/3=110s$​，这非常的糟糕……

> [!note] 
>
> 这个问题通常被称为*护航效应（convoy effect）*，一些耗时较少的潜在资源消费者被排在重量级的资源消费者之后。

这是FIFO无法解决的问题，那我们就需要提出一种更好的解决方案，以解决这种令人无法接受的情况。

##### 最短任务优先（SJF）

*最短任务优先（Shortest Job First）*，这个名称也就是它的策略，先执行最短的任务，再执行次短任务。

现在让我们看看在此调度策略下上述例子的平均周转时间：$(10+20+120)/3=50s$

确实得到了良好的改善。事实上，在保持所有任务同时到达的假设下，SJF确实是最优的调度策略（这里最优的衡量标准是平均周转时间，在指标不变的情况下后文出现类似的表达也是这个意思）

但是现实总是不尽人意。我们放宽<u>假设2:假设工作现在可以随时到达。</u>

问题来了，在A任务到达后，由于当前只有A任务到达，于是操作系统选择执行最短的A，执行一段时间B到达了，即使B任务时间仅仅是A的十分之一，但是不好意思，A在执行，SJF策略要等待A执行完毕，再运行最短的任务。显然这种情况下的平均周转时间一定很糟糕……

##### 最短完成时间优先（STCF）

为了解决上述SJF遇到的问题，我们还需要<u>放宽假设3:工作不一定需要一直运行直到结束。</u>

也就是说，进程可以被抢占，进程之间可以通过一定的机制抢占cpu，以达到我们的调度策略目标。

*最短完成时间优先（Shortest Time-to-Completion First，STCF）*完全就是这么做的，每当新工作进入系统时，它会确定剩余工作和新工作中，谁的剩余时间最少，然后调度该工作。

考虑我们的新假设，STCF就是最优的，如果考虑所有工作同时到达，SJF就是最优的。

##### 新的衡量指标：响应时间

在我们已知任务执行时间和任务只使用cpu时，唯一的衡量指标就是周转时间。可是现实不会让我们过的这么轻松。由于分时系统的存在，操作系统允许用户一边听音乐，一边坐在中断面前等待终端的输出——这要求系统有很好的交互性。

交互性也就意味着，用户在终端输入命令后，系统应该及时反馈，于是我们引入一个新的衡量指标：*响应时间（response time）*。响应时间被定义为从任务到达系统到首次运行的时间。

$T_{响应时间}=T_{首次运行}-T_{到达时间}$

加入该衡量指标，我们联想之前的调度策略，它们在响应时间上并不是很友好。

于是，我们应该如何构建一个对响应时间敏感的系统？

##### 轮转

为了解决这个问题，我们将介绍一种新的调度算法，通常被称为*轮转（Round-Robin， RR）*调度。基本思想很简单：RR在一个*时间片（time slice，有时被称为调度量子， scheduling quantum）*内运行一个工作，然后切换到运行队列的下一个任务，而不是一直运行一个任务直到结束。

> [!warning]
>
> 请注意，时间片的长度必须是<u>时钟中断周期的倍数</u>。

不再举例说明，时间片越短，在响应时间的表现上会越好，但是，太短的时间片会带来新的问题：突然上下文切换的成本将会影响整体性能。因此系统设计者需要权衡时间片的长度，使其足够长，以便能够*摊销（amortize）*上下文切换成本，而又能保证系统及时响应。

> [!note] 摊销可以减少成功
>
> 当某些系统操作存在固有成本时，通常会使用摊销技术。通过减少成本的频度，也就是减少执行次数，系统对于这些操作的总成本就会降低。例如，时间片设置为10ms，且上下文切换需要1ms，那么需要浪费10%时间用于上下文切换。现在要摊销这个成本，可以把时间片增加到100ms，在这种情况下，仅1%的时间用于上下文切换，因此时间片带来的成本就被摊销了。

提醒一下，上下文切换的成本不仅仅是保存和恢复少量寄存器所造成的。程序运行时，它们在在cpu高速缓存、tlb、分支预测器和其他片上硬件中建立了大量的状态。切换进程会导致这些状态刷新，且新进程也需要更新相关的状态，这可能会导致成本大大增加。

我们当前还是建立在性能指标只有响应时间的基础上的，如果加入周转时间呢，实际上，RR调度在周转时间上表现是非常差的，甚至很多情况下不如FIFO。

更一般的说，任何公平的调度策略（比如RR就是，每个时间片调度一个进程）在周转时间上的表现都不好。这同样也是一种权衡，鱼与熊掌不可兼得，不能既要又要。

总结一下，至此我们已经提出了两种调度策略：

1. 针对周转时间：SJF，STCF，但是对响应时间不利
2. 针对响应时间：RR，但是对周转时间不利

并且我们还有两个假设需要放宽：假设4（作业没有I/O）和假设5（每个作业运行时间是已知的）

> [!tip] 重叠可以提高利用率
>
> 重叠（overlap）操作可以最大限度的提高系统利用率。比如执行磁盘I/O操作时，可以切换进程执行。任何一种情况下，开始操作然后切换到其他工作都是一个好主意，这也提高了系统的整体利用率和效率。

##### 结合I/O

<u>放宽假设4:所有程序都可能执行I/O操作。</u>

正在运行的作业在I/O期间，不会使用CPU，它被阻塞直到I/O完成。这段时间对于CPU而言如果什么都不干是非常浪费的，因此调度程序需要在某个进程发起I/O操作时，及时切换到另一个进程以充分利用cpu，并且在原来进程I/O操作完成后及时切换回去，以保证良好的响应性。操作系统如何处理？也就是说这样的调度策略应该是怎样的？

比如现在有两项工作A和B，每项工作需要50ms的cpu时间，两者区别就是对于A，每隔10ms发起一个IO请求，并且每个I/O都需要10ms，而B只是使用CPU50ms，不执行I/O。调度程序先执行A后执行B。

假设我们正在尝试构建一个STCF调度程序。这样的程序需要如何考虑将A分解成5个10ms子工作，而B仅仅是单个50msCPU需求？显然，仅运行一个工作，而不考虑如何I/O是没有意义的。

一种常见的做法就是将A的每个10ms子任务都认为是一项独立的工作。因此，操作系统启动时，它的选择是调度10ms的A，还是50ms的B。对于STCF是明确的，选择较短的一个，然后开始执行，在这种情况下是A，然后A进入I/O，只剩下B，B开始执行，然后提交A一个新的子任务，它抢占B并运行10ms。这样做也就实现了前文提到的*重叠（overlap）*。一个进程在等待另一个进程的I/O完成时使用CPU，系统利用率也得到了提升。

因此我们可能找到了一种基本的解决方案：通过将每个CPU突发作为一项工作，调度程序确保“交互”进程的正常运行。当这些交互式作业正在执行I/O时，其他CPU密集型作业即将运行 ，从而更好的利用cpu。

##### 无法预知

有了应对I/O的基本方法，我们来到了最后的假设：调度程序知道每个工作的长度。

这太糟糕了！调度程序怎么可能会知道每个工作的长度。现实情况就是：大部分作业的长度操作系统是无法得知的！

因此我们的任务就成了如何建立一种没有这样先验知识的SJF/STCF？或者说，我们如何将已经得到的一些想法与RR调度结合起来，以便响应时间也有个不错的表现？

#### 调度：多级反馈队列

本章介绍一种著名的调度方法——*多级队列反馈（Multi-level Feedback Queue， MLFQ）*

多级反馈队列需要解决前文调度方法无法同时满足的两个问题：

1. 优化周转时间
2. 降低响应时间

正如上述，我们对即将到来的作业没有先验知识，也就是我们无法预测未来。如何解决？

> [!tip] 从历史中学习
>
> 多级反馈队列是利用历史经验预测未来的一个例子，操作系统中还有很多地方才用了这种思路。如果工作存在着某种阶段性的行为，那么就可以预测，这种思路就有的谈。

##### MLFQ：基本规则

与基本调度一样，我们首先介绍一些基本规则，或者说一些很容易理解的规则，加入更加严格的现实条件后，我们再优化（重写）这些规则。

MLFQ中有许多队列，每个队列具有不同的优先级。任何时刻，工作只能存在于一个队列中，操作系统会优先执行优先级更高的队列中的工作，对于处于同一个优先级队列中的工作才用RR调度策略。

关键问题在于如何设置优先级，也就是说我们怎样判断什么样的进程优先级是高的，什么样的进程优先级是短的。MLFQ的思路就是通过观察某个进程的行为，来判断将来的一段时间是否再次被响应，比如如果一个进程发起了一个I/O操作，那么我们认为它将来可能需要再次调用，因此这是一个交互型的进程，需要较短的响应时间，因此我们就把它放在较高的优先级队列；相反，如果一个进程长时间占用cpu，那么MLFQ就降低其优先级。

两个基本规则：

- **规则1**：如果A的优先级>B的优先级，运行A而不运行B。
- **规则**：如果A的优先级=B的优先级，轮转运行

##### 如何改变优先级

我们必须决定，在一个工作生命周期中，MLFQ如何改变优先级。要做到这一点，我们需要回顾上文提到的，需要记住工作的特点：既有运行时间很短、频繁放弃CPU的交互型工作，也有需要很多CPU时间、响应时间不重要的长时间计算密集型工作。因此我们下面定义最基础的优先级调整算法：

- **规则3**：工作进入系统时，放在最高优先级队列中
- **规则4a**：工作用完整个时间片后，降低其优先级（移入下一个队列）
- **规则4b**：如果工作在其时间片内主动释放了CPU，则优先级不变。

这里规则4b主动释放CPU也就意味着这个工作是一个交互型工作，因此应该保持高优先级以保证较低的响应时间。

事实上，以上的规则，在某种情况下是近似SJF的。

###### 假设来了一个长工作A

并且假设该长工作是一个cpu密集型工作，那么根据上述的规则，从最高优先级队列，每运行一个时间片，就会降到低一个级别的队列中，一直降低最低并一直待在那里。

###### 此时来一个短工作B

假设A运行一段时间后，来了一个较短工作B，此时根据规则3，进入系统时优先级最高，于是先执行B，由于B很短，可能还没有降低到最低优先级队列中已经执行完了，因此此种情况下，MLFQ表现为SJF。

###### 又来了一个带有I/O的工作

根据规则4b，只要该工作在一个时间片内主动放弃了cpu，那么优先级不变。

至此，MLFQ看起来运行良好，长工作好像也可以公平的共享cpu，又可以保证短工作和交互型作业很好的响应时间。然而，仔细想想这样的规则有一些非常严重的缺点！

##### 简单的MLFQ存在的问题

1. 长工作饥饿问题

   如果有很多交互型作业或者不断有新的短作业进入系统，长工作就会一直得不到调度，因此会造成饥饿问题

2. 愚弄调度程序

   聪明的用户可能会写出这样的程序：进程在用完一个时间片之前，进行一次无关紧要的I/O，比如访问一个文件。根据我们的规则，此进程会一直占据cpu而不释放，无法保证公平性。

3. 长工作后续也可能会有交互型操作

   一个程序不同时间可能表现不同的行为，如果一个计算密集型工作在某段时间需要进程交互型操作，但是由于根据我们的规则4a，它已经逐渐降低到低优先级队列了，因此也就无法享受系统中其他交互型作业的待遇，响应时间得不到很好的保证。

##### 尝试提升优先级

解决饥饿问题，我们可以周期性的提升所有工作的优先级。一种简单但有效的做法是：每隔一段时间，将所有的工作都扔到最高优先级队列，于是我们添加新的规则：

- **规则5**：经过一段时间S，就将系统中所有的工作重新加入到最高优先级队列。

新规则解决了前文提到的两个问题：首先进程不会被饿死。其次一个cpu密集型工作如果表现为交互型，通过优先级提升，调度程序也会正确的对待它。

添加时间S导致了一个新的问题：S的值要如何设置才能保证长工作既不会饥饿，交互型工作又能得到很好的响应。这种值被著名的系统研究员John Ousterhout称为*巫毒长量（voo-doo-constant）*。

##### 更好的计时方式

只剩下最后一个问题：如何防止程序被愚弄？导致调度程序被愚弄的根源就是规则4a和规则4b，导致只要在时间片内释放cpu，就保留它的优先级。

这里的解决方案，是为MLFQ的每层队列提供更完善的*CPU计时方式（accounting）*。调度程序应该记录一个进程在每一层消耗的总时间，而不是在调度时重新计时，只要进程完成了自己在这一层的时间份额，那么就降低它的优先级，不管是一次用完的还是好几次用完的。因此我们重写规则4a和4b。

- **规则4**：一旦工作完成了其在某一层的时间配额（无论中间主动释放了多少次CPU），就降低其优先级（移入低一级队列）

##### 总结

重新总结优化后的MLFQ规则

1. 如果A的优先级>B的优先级，运行A不运行B
2. 如果A的优先级=B的优先级，轮转运行AB
3. 工作进入系统时，放在最高优先级
4. 一旦工作用完了其在某一层的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级（移入到低一级队列）
5. 经过一段时间S，就将系统中所有工作重新加入到最高优先级队列





## 并发

## 持久