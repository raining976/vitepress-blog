# 操作系统导论

> [!TIP]
>
> 本文将从 虚拟化（virtulization）、并发（concurrency）、持久性（persistence）这部分介绍操作系统是如何进行工作的，包括如何决定接下来哪个程序使用cpu，如何在虚拟内存系统中处理内存使用过载，虚拟机监控器如何工作，如何处理磁盘上的数据等等。

操作系统三个设计目标

1. 建立抽象，方便程序使用
2. 提供高性能
3. 在应用程序之间以及os和应用之间提供保护

## 虚拟化

什么是虚拟化，操作系统可以认为是一个通用的计算机软件，它向其他更接近用户层的应用程序提供了许多通用的接口，操作系统允许程序共享内存、允许程序与设备进行交互等等，不同的程序对计算机资源的使用要求可能是不同的，因此我们希望对于不同需求的应用程序所能看到的资源都是一样的形式，这也算是一种透明，虚拟化就是做了一件这样的事：它让物理资源（处理器、内存、磁盘等）转换为更加通用、更强大且更容易使用的虚拟形式。无非虚拟化cpu就是让每个应用程序都认为自己是独占cpu的，虚拟化内存让每个程序都认为自己是独占内存空间的，程序与程序之间不知道对方的存在。

### 虚拟化cpu

在讲虚拟化cpu之前，我们首先要介绍一个对于前文提到的“应用程序”的一种抽象：进程。

#### 进程

进程是操作系统提供的最基本的抽象，进程的定义也非常的简单：<u>进程就是运行中的程序。</u>程序本身是没有生命周期的，本质上是一些指令，是操作系统让程序运行起来从而发挥作用的。

> [!NOTE]
>
> 一个非常常见的需求：多个程序需要同时运行，但是计算机刚发展时是单cpu的，操作系统如何实现每个程序都能“同时”使用到cpu，从而实现我们的需求？

事实上实现这件事也就是实现了虚拟化cpu。

通过让一个进程只运行一小段时间（我们称这一小段时间为一个*时间片*），然后切换到其他进程，这样操作系统也就提供了存在多个cpu的假象。这就是时分共享（time sharing）cpu技术。

辩证的看待这个方案，潜在的问题就是效率降低，因为cpu共享进程就要切换，就会有上下文切换的额外性能损失。

如何高效进行cpu共享，这就需要用到操作系统的一些低阶的机制以及一些高阶的智能。所谓的机制就是”怎么切换进程”，需要配合硬件等实现上下文切换之类的事情；而策略就是“切换哪些进程”，涉及到一些算法，什么时候切换哪些进程。

为了实现我们的终极目标，我们还需要搞清楚：到底什么是进程？

##### 究竟什么是进程？进程需要包含哪些信息？

重申一下：进程就是操作系统对正在运行的程序提供的抽象。进程就是一个正在运行的程序，任何时候，只要我们知道了一个进程访问或者影响了系统的哪些部分，我们也就知道了进程具体是什么了。

为了进一步理解究竟什么是进程，我们就需要理解它每时每刻能影响系统的哪些状态，我们称这些状态为机器状态（machine state）：程序在运行时可以更新或者读取的内容。

所谓进程的机器状态有一个最明显也是最重要的组成部分：<u>内存</u>。程序的指令存在内存中，进程要读写的数据也在内存中，所以进程可以访问的内存也是进程的一部分（很显然，不是吗）

> [!TIP]
>
> 进程能访问的内存也称为地址空间（address space）这部分将在虚拟化内存中详细介绍。

进程的机器状态另一部分就是<u>寄存器</u>。寄存器是一种比所谓的缓存更加高速的缓存硬件。很多时候为了提升计算效率，寄存器也是进程频繁操作的目标，因此也属于进程的一部分。

特别的，有些特殊的寄存器可以认为是每个进程的必需品，比如程序计数器（Program Counter PC有时叫做指令指针，Instruction Pointer IP），栈指针、帧指针等管理函数参数、局部变量和返回地址等，这些也属于进程的一部分。

##### 进程创建要做的一些事情

操作系统创建进程必须要做的第一件事就是将代码和所有静态数据加载到内存中，也就是加载到内存的地址空间中。当然现代操作系统都是惰性加载的，即仅在程序执行期间需要加载某些代码或者数据时才会加载，具体的细节在将来的分页和交换机制中会了解到。（本质上就是只存一个在磁盘中的位置，需要的时候再从磁盘加载，当然存储的信息不只有磁盘位置这么点）

将（必要的）代码和静态数据加载到内存后，操作系统还需要为程序运行时栈分配一些内存，这个栈用来存储程序中的局部变量、函数参数和返回地址中（以c语言为例）。有时操作系统可能会初始化栈中的某些信息，比如main函数的参数列表等。

除了为栈分配内存，还可能会为程序的堆分配内存。C程序中使用malloc显式的为程序分配堆空间。

还有一些其他的初始任务，特别是与I/O相关的任务。比如在UNIX系统，默认情况下每个进程都会有三个打开的文件描述符，用于进行标准的输入、输出和错误。这些描述符可以让程序轻松的读取来自终端的输入以及打印输出到屏幕。关于这部分将在持久化中详细了解。

至此，操作系统终于为程序执行搭建了所有需要的内容，然后最后一件事情就是：启动程序。通过将程序跳转到main函数位置，将cpu控制权交给新创建的进程，从而程序开始执行。

##### 进程有哪些状态

不同的时间进程可能会有不同的表现，这也是为了达到某些目的而使用的一种手段，我们称为进程的状态

- 运行（running）：进程正在处理上运行。
- 就绪（ready）：进程已经准备上执行，但是由于某种原因，操作系统并没有选择在此时执行。
- 阻塞（blocked）：当前进程由于执行了某种操作（比如io操作）而处于的一种状态，直到发生其他事件时才会准备运行。

![进程状态](https://gitee.com/raining976/markdown-imgs/raw/master/img/image-20241001195028550.png)

从就绪到运行意味着该进程已经被调度；从运行到就绪意味着该进程已经取消调度。

一旦进程被阻塞，OS将保持进程的这种状态，直到发生某种事件（比如io完成），此时进程再次转入就绪状态（也可能直接执行，这由操作系统决定）

##### 如何跟踪进程

真实的操作系统中的关于进程跟踪的数据结构往往特别复杂，首先必要的结构是寄存器上下文，进程在切换时，所依赖的各种寄存器的值需要被保存，保存到哪里？保存到进程所在的内存位置，通过恢复寄存器（将内存中的这些值重新赋值回实际的物理寄存器中）。这个保存又恢复（恢复另一个）的过程也称为上下文切换（context switch）

保存寄存器上下文的数据结构可能长这个样：

```c
struct context {
       int eip;
       int esp;
       int ebx;
       int ecx;
       int edx;
       int esi;
       int edi;
       int ebp;
};
```

除此之外，还有进程本身的一些内容也需要跟踪，可能是这样的结构：

```c

// the different states a process can be in
enum proc_state { UNUSED, EMBRYO, SLEEPING,
               RUNNABLE, RUNNING, ZOMBIE };
// the information xv6 tracks about each process
// including its register context and state
struct proc {
  char *mem;							// 当前进程的开始内存
  uint sz;						  	// 进程空间大小
  char *kstack;						// 该进程的内核栈底
  enum proc_state state;	// 进程状态
  int pid;								// 进程id
  struct proc *parent;		// 父进程
  void *chan;							// If non-zero, sleeping on chan
  int killed;							// 不为0表示当前进程已被杀死
  struct file *ofile[NOFILE];  // 打开的文件
  struct inode *cwd;		 	// 当前目录
  struct context context;	// 上下文
  struct trapframe *tf;		// Trap frame for the current interrupt
};
```

有时候人们会将存储关于进程的信息的个体结构称为进程控制块（Process Control Block， PCB），这是谈论包含每个进程信息的c结构的一种方式。

#### 进程调用api（无关紧要的内容）

> [!note]
>
> 实践相关的内容

##### fork()

fork会生成一份与原来一模一样的代码，但是执行位置是从fork调用的位置执行，区分父进程和子进程的方式是通过fork返回的进程id，对于子进程来讲，返回的进程id就是0；对于父进程，返回的进程id就是一个比较大的整数，也就是子进程的进程id。

注意父子进程的执行顺序并不固定，这取决于操作系统如何进行调用。

fork父子进程共用同一份代码，现代操作系统实现时实际也是这么干的！在执行fork时并没有直接真正的拷贝一份内存空间到子进程，而是将子进程的虚拟内存（我们将在之后详细介绍这个概念）指向了与父进程一样的同一块物理内存，同时这两个进程对这部分内存的权限都是只读。这样只要父子进程不修改，看起来好像就是拷贝了一份似的！如果进程此时修改，那么会陷入操作系统，操作系统执行对应的陷阱程序，分配新的物理内存，也就是说，写的时候才进行拷贝，因此这种策略也称为*写时复制*。

##### wait()

可以控制父子进程之间的调用顺序，父进程调用wait()，就会延迟自己的执行，直到子进程执行完毕，wait()才会返回父进程。

##### exec()

exec是创建进程api的一个重要部分。该系统调用配合fork()可以让子进程执行与父进程不一样的程序。

exec传入执行的程序以及程序的参数列表，此时exec会从可执行程序中加载代码和静态数据，并用它覆写自己的代码段以及静态数据，堆、栈等其他内存空间也会被重新初始化。然后操作系统执行该程序。

实际上，它并没有创建新的程序，而是直接将当前运行的程序直接替换为了指定的那个程序，子进程执行exec后，就像从来没有执行过原来的程序一样，堆exec的调用也永远不会返回。

##### 为什么设计如此奇怪的api？

看起来很奇怪，实际上fork和exec分离的设计在构建UNIX shell的时候非常有用，因为这给了shell在fork之后exec之前运行代码的机会，这些代码可以在运行新的程序前改变环境，从而让一些看起来复杂的功能实现起来非常容易。

比如shell中的重定向命令：`>`

shell中实现非常容易，在完成子进程的创建之后，调用exec之前先关闭标准输出，然后打开输出的目标文件。这样运行的程序就会将结果发送到目标文件中了。

之所以可以这样顺理成章的被透明的写入目标文件而不是打印到屏幕，是基于对操作系统管理文件描述符的假设。具体来说，UNIX系统会从0开始寻找可以 使用的文件描述符，打开文件就意味着STDOUT_FILENO会成为第一个可用的文件描述符，因此子进程在对标准输出文件描述符写入时，写入的内容都会被透明的传输到新打开的文件。

实际上，UNIX管道符也是用类似的方式实现的，不过用的是pipe()系统调用。

#### 机制：受限直接执行

为了虚拟化cpu，也就是操作系统需要以一种方式让多个任务共享cpu，让它们看起来是同时运行的。基本的思想很简单：每个进程交替执行一段时间，这种方式称为*时分共享*

##### 两个问题

1. 性能问题：在不增加操作系统开销的情况下实现虚拟CPU。
2. 控制权问题：如何既共享cpu，又能保证cpu的控制权。

尤其是控制权，如果一个进程无限掌握cpu，那可能会造成无法预料的后果，这也是操作系统不愿意看到的。

> [!tip]
>
> 如何高效、可控的虚拟化CPU

##### 核心思路：受限直接执行

直接执行的含义很简单，就是让进程直接在cpu执行即可。

在没有限制的情况下，我们很容易想到，若操作系统想要启动某个程序，首先在进程列表里创建一个进程条目，为其分配内存，将代码加载到内存中，然后找到main函数入口，跳转到那里，并开始运行用户代码。此时也就完成了cpu控制权的转移。

接下来，按照我们预想的结果，用户程序顺利执行完代码，然后跳转回操作系统之前的位置，控制权换回来了。

可事实真的总是如我们想的这样吗？设想这样一种情况：用户代码进入了死循环。此时操作系统就永远无法获得cpu控制权了，这很糟糕。不仅如此，我们怎么保证程序不做操作系统不希望它做的事情？

因此进一步抛出两个问题：

1. 如果我们只运行一个程序，如何保证它不做我们不希望它做的事，同时高效运行它。
2. 当我们运行一个进程的时候，操作系统如何让它停下来并切换另一个进程。

##### 解决问题1:受限制的操作

为了解决问题1，我们让进程不能随便执行命令，而是限制它执行某些命令。

> [!note] 受保护的控制权转移
>
> 需要硬件与操作系统协作。也就是所谓的特权级架构：用户模式、内核模式。
>
> 用户模式下不能完全访问硬件资源，内核模式下操作系统可以访问机器的全部资源。
>
> 这种架构下提供了一种trap命令，用来从用户模式陷入到内核模式，让操作系合法的做“用户程序想要做却不能做的事”。包括返回陷阱指令，返回到用户模式。

用户程序如果想要执行某种特权操作，应该怎么做？几乎所有的现代硬件都提供给用户程序执行系统调用的能力，我们称之为*系统调用*。但是要执行系统调用，用户程序必须要陷入内核，将特权提升到内核模式，此时又操作系统为用户程序执行它想要执行的特权操作，执行完成通过陷阱返回指令返回到用户程序，同时特权级别降到用户级别。

## 并发

## 持久