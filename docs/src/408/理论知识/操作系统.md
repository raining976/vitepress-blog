---
description: 操作系统的理论知识 操作系统基础知识
---



# 操作系统（操作系统导论）

> [!TIP]
>
> 本文将从 虚拟化（virtulization）、并发（concurrency）、持久性（persistence）这部分介绍操作系统是如何进行工作的，包括如何决定接下来哪个程序使用cpu，如何在虚拟内存系统中处理内存使用过载，虚拟机监控器如何工作，如何处理磁盘上的数据等等。

操作系统三个设计目标

1. 建立抽象，方便程序使用
2. 提供高性能
3. 在应用程序之间以及os和应用之间提供保护

## 虚拟化

什么是虚拟化，操作系统可以认为是一个通用的计算机软件，它向其他更接近用户层的应用程序提供了许多通用的接口，操作系统允许程序共享内存、允许程序与设备进行交互等等，不同的程序对计算机资源的使用要求可能是不同的，因此我们希望对于不同需求的应用程序所能看到的资源都是一样的形式，这也算是一种透明，虚拟化就是做了一件这样的事：它让物理资源（处理器、内存、磁盘等）转换为更加通用、更强大且更容易使用的虚拟形式。无非虚拟化cpu就是让每个应用程序都认为自己是独占cpu的，虚拟化内存让每个程序都认为自己是独占内存空间的，程序与程序之间不知道对方的存在。

### 虚拟化cpu

在讲虚拟化cpu之前，我们首先要介绍一个对于前文提到的“应用程序”的一种抽象：进程。

#### 进程

进程是操作系统提供的最基本的抽象，进程的定义也非常的简单：<u>进程就是运行中的程序。</u>程序本身是没有生命周期的，本质上是一些指令，是操作系统让程序运行起来从而发挥作用的。

> [!NOTE]
>
> 一个非常常见的需求：多个程序需要同时运行，但是计算机刚发展时是单cpu的，操作系统如何实现每个程序都能“同时”使用到cpu，从而实现我们的需求？

事实上实现这件事也就是实现了虚拟化cpu。

通过让一个进程只运行一小段时间（我们称这一小段时间为一个*时间片*），然后切换到其他进程，这样操作系统也就提供了存在多个cpu的假象。这就是时分共享（time sharing）cpu技术。

辩证的看待这个方案，潜在的问题就是效率降低，因为cpu共享进程就要切换，就会有上下文切换的额外性能损失。

如何高效进行cpu共享，这就需要用到操作系统的一些低阶的机制以及一些高阶的智能。所谓的机制就是”怎么切换进程”，需要配合硬件等实现上下文切换之类的事情；而策略就是“切换哪些进程”，涉及到一些算法，什么时候切换哪些进程。

为了实现我们的终极目标，我们还需要搞清楚：到底什么是进程？

##### 究竟什么是进程？进程需要包含哪些信息？

重申一下：进程就是操作系统对正在运行的程序提供的抽象。进程就是一个正在运行的程序，任何时候，只要我们知道了一个进程访问或者影响了系统的哪些部分，我们也就知道了进程具体是什么了。

为了进一步理解究竟什么是进程，我们就需要理解它每时每刻能影响系统的哪些状态，我们称这些状态为机器状态（machine state）：程序在运行时可以更新或者读取的内容。

所谓进程的机器状态有一个最明显也是最重要的组成部分：<u>内存</u>。程序的指令存在内存中，进程要读写的数据也在内存中，所以进程可以访问的内存也是进程的一部分（很显然，不是吗）

> [!TIP]
>
> 进程能访问的内存也称为地址空间（address space）这部分将在虚拟化内存中详细介绍。

进程的机器状态另一部分就是<u>寄存器</u>。寄存器是一种比所谓的缓存更加高速的缓存硬件。很多时候为了提升计算效率，寄存器也是进程频繁操作的目标，因此也属于进程的一部分。

特别的，有些特殊的寄存器可以认为是每个进程的必需品，比如程序计数器（Program Counter PC有时叫做指令指针，Instruction Pointer IP），栈指针、帧指针等管理函数参数、局部变量和返回地址等，这些也属于进程的一部分。

##### 进程创建要做的一些事情

操作系统创建进程必须要做的第一件事就是将代码和所有静态数据加载到内存中，也就是加载到内存的地址空间中。当然现代操作系统都是惰性加载的，即仅在程序执行期间需要加载某些代码或者数据时才会加载，具体的细节在将来的分页和交换机制中会了解到。（本质上就是只存一个在磁盘中的位置，需要的时候再从磁盘加载，当然存储的信息不只有磁盘位置这么点）

将（必要的）代码和静态数据加载到内存后，操作系统还需要为程序运行时栈分配一些内存，这个栈用来存储程序中的局部变量、函数参数和返回地址中（以c语言为例）。有时操作系统可能会初始化栈中的某些信息，比如main函数的参数列表等。

除了为栈分配内存，还可能会为程序的堆分配内存。C程序中使用malloc显式的为程序分配堆空间。

还有一些其他的初始任务，特别是与I/O相关的任务。比如在UNIX系统，默认情况下每个进程都会有三个打开的文件描述符，用于进行标准的输入、输出和错误。这些描述符可以让程序轻松的读取来自终端的输入以及打印输出到屏幕。关于这部分将在持久化中详细了解。

至此，操作系统终于为程序执行搭建了所有需要的内容，然后最后一件事情就是：启动程序。通过将程序跳转到main函数位置，将cpu控制权交给新创建的进程，从而程序开始执行。

##### 进程有哪些状态

不同的时间进程可能会有不同的表现，这也是为了达到某些目的而使用的一种手段，我们称为进程的状态

- 运行（running）：进程正在处理上运行。
- 就绪（ready）：进程已经准备上执行，但是由于某种原因，操作系统并没有选择在此时执行。
- 阻塞（blocked）：当前进程由于执行了某种操作（比如io操作）而处于的一种状态，直到发生其他事件时才会准备运行。

![进程状态](https://gitee.com/raining976/markdown-imgs/raw/master/img/image-20241001195028550.png)

从就绪到运行意味着该进程已经被调度；从运行到就绪意味着该进程已经取消调度。

一旦进程被阻塞，OS将保持进程的这种状态，直到发生某种事件（比如io完成），此时进程再次转入就绪状态（也可能直接执行，这由操作系统决定）

##### 如何跟踪进程

真实的操作系统中的关于进程跟踪的数据结构往往特别复杂，首先必要的结构是寄存器上下文，进程在切换时，所依赖的各种寄存器的值需要被保存，保存到哪里？保存到进程所在的内存位置，通过恢复寄存器（将内存中的这些值重新赋值回实际的物理寄存器中）。这个保存又恢复（恢复另一个）的过程也称为上下文切换（context switch）

保存寄存器上下文的数据结构可能长这个样：

```c
struct context {
       int eip;
       int esp;
       int ebx;
       int ecx;
       int edx;
       int esi;
       int edi;
       int ebp;
};
```

除此之外，还有进程本身的一些内容也需要跟踪，可能是这样的结构：

```c

// the different states a process can be in
enum proc_state { UNUSED, EMBRYO, SLEEPING,
               RUNNABLE, RUNNING, ZOMBIE };
// the information xv6 tracks about each process
// including its register context and state
struct proc {
  char *mem;							// 当前进程的开始内存
  uint sz;						  	// 进程空间大小
  char *kstack;						// 该进程的内核栈底
  enum proc_state state;	// 进程状态
  int pid;								// 进程id
  struct proc *parent;		// 父进程
  void *chan;							// If non-zero, sleeping on chan
  int killed;							// 不为0表示当前进程已被杀死
  struct file *ofile[NOFILE];  // 打开的文件
  struct inode *cwd;		 	// 当前目录
  struct context context;	// 上下文
  struct trapframe *tf;		// Trap frame for the current interrupt
};
```

有时候人们会将存储关于进程的信息的个体结构称为进程控制块（Process Control Block， PCB），这是谈论包含每个进程信息的c结构的一种方式。

#### 进程调用api（无关紧要的内容）

> [!note]
>
> 实践相关的内容

##### fork()

fork会生成一份与原来一模一样的代码，但是执行位置是从fork调用的位置执行，区分父进程和子进程的方式是通过fork返回的进程id，对于子进程来讲，返回的进程id就是0；对于父进程，返回的进程id就是一个比较大的整数，也就是子进程的进程id。

注意父子进程的执行顺序并不固定，这取决于操作系统如何进行调用。

fork父子进程共用同一份代码，现代操作系统实现时实际也是这么干的！在执行fork时并没有直接真正的拷贝一份内存空间到子进程，而是将子进程的虚拟内存（我们将在之后详细介绍这个概念）指向了与父进程一样的同一块物理内存，同时这两个进程对这部分内存的权限都是只读。这样只要父子进程不修改，看起来好像就是拷贝了一份似的！如果进程此时修改，那么会陷入操作系统，操作系统执行对应的陷阱程序，分配新的物理内存，也就是说，写的时候才进行拷贝，因此这种策略也称为*写时复制*。

##### wait()

可以控制父子进程之间的调用顺序，父进程调用wait()，就会延迟自己的执行，直到子进程执行完毕，wait()才会返回父进程。

##### exec()

exec是创建进程api的一个重要部分。该系统调用配合fork()可以让子进程执行与父进程不一样的程序。

exec传入执行的程序以及程序的参数列表，此时exec会从可执行程序中加载代码和静态数据，并用它覆写自己的代码段以及静态数据，堆、栈等其他内存空间也会被重新初始化。然后操作系统执行该程序。

实际上，它并没有创建新的程序，而是直接将当前运行的程序直接替换为了指定的那个程序，子进程执行exec后，就像从来没有执行过原来的程序一样，堆exec的调用也永远不会返回。

##### 为什么设计如此奇怪的api？

看起来很奇怪，实际上fork和exec分离的设计在构建UNIX shell的时候非常有用，因为这给了shell在fork之后exec之前运行代码的机会，这些代码可以在运行新的程序前改变环境，从而让一些看起来复杂的功能实现起来非常容易。

比如shell中的重定向命令：`>`

shell中实现非常容易，在完成子进程的创建之后，调用exec之前先关闭标准输出，然后打开输出的目标文件。这样运行的程序就会将结果发送到目标文件中了。

之所以可以这样顺理成章的被透明的写入目标文件而不是打印到屏幕，是基于对操作系统管理文件描述符的假设。具体来说，UNIX系统会从0开始寻找可以 使用的文件描述符，打开文件就意味着STDOUT_FILENO会成为第一个可用的文件描述符，因此子进程在对标准输出文件描述符写入时，写入的内容都会被透明的传输到新打开的文件。

实际上，UNIX管道符也是用类似的方式实现的，不过用的是pipe()系统调用。

#### 机制：受限直接执行

为了虚拟化cpu，也就是操作系统需要以一种方式让多个任务共享cpu，让它们看起来是同时运行的。基本的思想很简单：每个进程交替执行一段时间，这种方式称为*时分共享*

##### 两个问题

1. 性能问题：在不增加操作系统开销的情况下实现虚拟CPU。
2. 控制权问题：如何既共享cpu，又能保证cpu的控制权。

尤其是控制权，如果一个进程无限掌握cpu，那可能会造成无法预料的后果，这也是操作系统不愿意看到的。

> [!tip]
>
> 如何高效、可控的虚拟化CPU

##### 核心思路：受限直接执行

直接执行的含义很简单，就是让进程直接在cpu执行即可。

在没有限制的情况下，我们很容易想到，若操作系统想要启动某个程序，首先在进程列表里创建一个进程条目，为其分配内存，将代码加载到内存中，然后找到main函数入口，跳转到那里，并开始运行用户代码。此时也就完成了cpu控制权的转移。

接下来，按照我们预想的结果，用户程序顺利执行完代码，然后跳转回操作系统之前的位置，控制权换回来了。

可事实真的总是如我们想的这样吗？设想这样一种情况：用户代码进入了死循环。此时操作系统就永远无法获得cpu控制权了，这很糟糕。不仅如此，我们怎么保证程序不做操作系统不希望它做的事情？

因此进一步抛出两个问题：

1. 如果我们只运行一个程序，如何保证它不做我们不希望它做的事，同时高效运行它。
2. 当我们运行一个进程的时候，操作系统如何让它停下来并切换另一个进程。

##### 解决问题1:受限制的操作

为了解决问题1，我们让进程不能随便执行命令，而是限制它执行某些命令。

> [!note] 受保护的控制权转移
>
> 需要硬件与操作系统协作。也就是所谓的特权级架构：用户模式、内核模式。
>
> 用户模式下不能完全访问硬件资源，内核模式下操作系统可以访问机器的全部资源。
>
> 这种架构下提供了一种trap命令，用来从用户模式陷入到内核模式，让操作系合法的做“用户程序想要做却不能做的事”。包括返回陷阱指令，返回到用户模式。

用户程序如果想要执行某种特权操作，应该怎么做？几乎所有的现代硬件都提供给用户程序执行系统调用的能力，我们称之为*系统调用*。但是要执行系统调用，用户程序必须要陷入内核，将特权提升到内核模式，此时又操作系统为用户程序执行它想要执行的特权操作，执行完成通过陷阱返回指令返回到用户程序，同时特权级别降到用户级别。

还有一个比较关键的问题：就是在程序陷入时，陷阱如何知道要在OS内运行哪些代码？

显然这不能让程序指定，程序是不被信任的。操作系统通过在系统时设置*陷阱表*来实现，陷阱表就是告诉硬件在发生某些异常时，要运行哪些代码。

下表总结了受限直接运行协议：

| 操作系统@启动（内核模式）                                    | 硬件                                                         |                                    |
| :----------------------------------------------------------- | ------------------------------------------------------------ | ---------------------------------- |
| 初始化陷阱表                                                 |                                                              |                                    |
|                                                              | 记住系统调用处理程序的地址                                   |                                    |
| 操作系统@运行（内核模式）                                    | 硬件                                                         | 应用程序                           |
| 在进程列表创建条目<br />为程序分配内存<br />将程序加载到内存<br />根据argv设置程序栈<br />用寄存器/程序计数器填充内核栈<br />从陷阱返回 |                                                              |                                    |
|                                                              | 从内核栈恢复寄存器<br />转向用户模式<br />跳到main           |                                    |
|                                                              |                                                              | 运行main<br />……<br />             |
|                                                              |                                                              | 调用系统调用<br />陷入操作系统     |
|                                                              | 将寄存器保存到内核栈<br />转向内核模式<br />跳到陷阱处理程序 |                                    |
| 处理陷阱<br />做系统调用的工作<br />从陷阱返回               |                                                              |                                    |
|                                                              | 从内核栈恢复寄存器<br />转向用户模式<br />跳到陷阱之后的程序计数器 |                                    |
|                                                              |                                                              | 从main返回<br />陷入（通过exit()） |
| 释放进程的内存<br />将进程从进程列表中清除                   |                                                              |                                    |

我们可以看到，LDE协议有两个阶段。

1. 系统引导阶段：内核初始化陷阱表，并且硬件记住它们的位置以供将来使用
2. 运行进程阶段：在使用从陷阱返回指令执行进程之前，内核先设置了一些有关于进程的内容，然后切换到用户模式，开始执行进程。当进程希望发出系统调用时，会重新陷入操作系统，然后再次通过从陷阱返回，将控制权还给进程。直到进程完成所有的main代码，通过exit系统调用，陷入os，os清理该进程相关内容，进程到此也全部完成并正常退出了。

##### 解决问题2:在进程之间切换

> [!tip] 关键问题
>
> 操作系统如何重新获得cpu控制权？

###### 协作方式：等待系统调用

这与LDE协议中的过程类似，操作系统信任程序会在一段时间之后发起系统调用，然后cpu控制权转移给内核。显然，这种被动的方式不太合理，设想一个进程获取cpu控制权后进入了无限循环，此时操作系统将彻底失去对cpu的控制。

###### 非协作时：操作系统主动控制

最无脑的方式：重新启动计算机。开个玩笑。

关键问题就是**如何在进程不配合的情况下，操作系统还能重新拿回cpu的控制权？**

答案很简单，许多年前构建计算机系统的许多人都发现了：*时钟中断（timer interrupt）*

时钟设备可以编程为每隔几毫秒产生一次中断，产生中断时，当前运行的进程中止，操作系统中预先配置的中断处理成会运行，此时os也就重新拿回的cpu控制权，继续做它想做的事情，比如停止当前进程，启动另一个进程。

> [!important]
>
> 很容易看出来，时钟中断对帮助**操作系统维持机器的控制权**至关重要。

产生中断时，硬件也做一些事情。为正在运行的程序保存足够的状态，以便在下次继续执行进程时正确恢复。

###### 保存和恢复上下文

如果os在中断后选择停止当前进程，启动另一个进程。那么就需要为当前的正在执行的进程保存一些寄存器的值（可能保存到它的内核栈），并为即将要执行的进程恢复一些寄存器的值（从它的内核栈），这就是*上下文切换（context switch）*的概念。这样一来，操作系统执行从陷阱返回指令就不会回到原来的进程了，还是继续执行另一个进程。

下面详细介绍了时钟中断并切换进程时os和硬件要做的事情：

| 操作系统@启动（内核模式）                                    | 硬件                                                         |          |
| ------------------------------------------------------------ | ------------------------------------------------------------ | -------- |
| 初始化陷阱表                                                 |                                                              |          |
|                                                              | 记住以下地址：<br />1. 系统调用处的地址<br />2. 时钟中断处理程序 |          |
| 启动中断时钟                                                 |                                                              |          |
|                                                              | 启动时钟<br />每隔x ms中断CPU                                |          |
| 操作系统@运行（内核模式）                                    | 硬件                                                         | 程序     |
|                                                              |                                                              | 进程A... |
|                                                              | 时钟中断<br />将寄存器（A）保存到内核栈（A）<br />转向内核模式<br />跳到陷阱处理程序 |          |
| 处理陷阱<br />调用switch()切换进程<br />将寄存器（A）保存到进程结构（A）<br />将进程结构（B）恢复到寄存器（B）<br />从陷阱返回（这时就会进入B） |                                                              |          |
|                                                              | 从内核栈（B）恢复寄存器（B）<br />转向用户模式<br />跳到B的程序计数器 |          |
|                                                              |                                                              | 进程B... |

注意这个过程有两种类型的寄存器保存/恢复：

1. 时钟中断时，将当前进程用到的寄存器保存在该**进程的内核栈**
2. 操作系统选择切换进程时，将原来的进程用到的寄存器值保存到**该进程的进程结构中**

> [!tip] 重新启动是有用的！
>
> 我们之前提到过，在协作式抢占时，无限循环的唯一解决方案就是reboot。虽然这看起来是个玩笑，但是研究表明，重启（或者通常意义上，重新开始运行一些软件）可能是构建强大系统非常有用的一个工具。
>
> 为什么这么说呢？首先重启可以让软件回到已知的状态，而这种状态往往是经过了大量的测试的状态。其次，重启可以回收旧的或者泄漏的资源，这些资源可能没有一种好的办法处理。最后，重启很容易自动化。常见的大规模集群的互联网服务中，系统管理软件会定期重启一些机器，以此来获得以上的好处。

至此，我们已经解决了如何保证os控制权以及如何进行进程切换的问题（上下文切换），接下来要解决的事情就是：进程切换时我们要运行哪个进程？这是进程调度程序必须要回答的问题，因此这是我们接下来研究的主题。

#### 进程调度

遵循我们一贯以来的想法，实现一个策略之前，我们做出一些关键的假设，以使得系统构建更加简单，未来我们会不断放宽这种假设，以使得其接近真实的世界。

##### 工作负载假设

我们对操作系统中运行的进程（有时也叫工作任务）作出如下假设

1. 每个工作运行相同的时间
2. 所有的工作同时到达
3. 一旦开始，每个工作保持运行直到完成
4. 所有的工作只是用CPU（也就是它们不执行io操作）
5. 每个工作的工作时间是已知的

这确实看起来是不现实的，但是这对我们构建一个完整健全的系统有一个很好的开始，因为一开始就罗列所有复杂的需求会让人不知道从何处着手。

##### 调度指标

什么样的调度是“好”的，我们需要给出定义这个“好”的标准。

这里为了简化我们只使用一个标准：*周转时间（turnaround time）*，这是一个性能指标。任务的周转时间指的是任务完成时间减去任务到达系统的时间。

$T_{周转时间}=T_{完成时间}-T_{到达时间}$​

我们最初的假设所有任务同时到达，因此在最严格的假设中，任务的周转时间也就是任务完成的时间。

##### 先进先出（FIFO）

最基本的一种非抢占式调度算法，有时也称为*先到先服务（First Come First，FCFS ）*。

FIFO有着最明显的优势：简单，容易实现。而且在我们最严格的假设下，它效果很好。

下面介绍一个例子来描述FIFO的调度策略。三个工作A、B、C，在大致相同的时间到达系统，因为需要明确先后顺序，于是我们就假设A比B早到一点点，B比C早到一点点。假设每个工作运行10s。这些工作的*平均周转（average turnaround time）*时间是多少？

A在10s时执行完成，B在20s时执行完成，C在30s时执行完成，因此平均周转时间为$(10+20+30)/3=20s$。这看起来还不错？

接下来我们<u>放宽假设1:每个任务的运行时间不再相同。</u>

假设A运行时间变为100s，B和C还是10s。接下来我们计算它们的平均周转时间：$(100+110+120)/3=110s$​，这非常的糟糕……

> [!note] 
>
> 这个问题通常被称为*护航效应（convoy effect）*，一些耗时较少的潜在资源消费者被排在重量级的资源消费者之后。

这是FIFO无法解决的问题，那我们就需要提出一种更好的解决方案，以解决这种令人无法接受的情况。

##### 最短任务优先（SJF）

*最短任务优先（Shortest Job First）*，这个名称也就是它的策略，先执行最短的任务，再执行次短任务。

现在让我们看看在此调度策略下上述例子的平均周转时间：$(10+20+120)/3=50s$

确实得到了良好的改善。事实上，在保持所有任务同时到达的假设下，SJF确实是最优的调度策略（这里最优的衡量标准是平均周转时间，在指标不变的情况下后文出现类似的表达也是这个意思）

但是现实总是不尽人意。我们放宽<u>假设2:假设工作现在可以随时到达。</u>

问题来了，在A任务到达后，由于当前只有A任务到达，于是操作系统选择执行最短的A，执行一段时间B到达了，即使B任务时间仅仅是A的十分之一，但是不好意思，A在执行，SJF策略要等待A执行完毕，再运行最短的任务。显然这种情况下的平均周转时间一定很糟糕……

##### 最短完成时间优先（STCF）

为了解决上述SJF遇到的问题，我们还需要<u>放宽假设3:工作不一定需要一直运行直到结束。</u>

也就是说，进程可以被抢占，进程之间可以通过一定的机制抢占cpu，以达到我们的调度策略目标。

*最短完成时间优先（Shortest Time-to-Completion First，STCF）*完全就是这么做的，每当新工作进入系统时，它会确定剩余工作和新工作中，谁的剩余时间最少，然后调度该工作。

考虑我们的新假设，STCF就是最优的，如果考虑所有工作同时到达，SJF就是最优的。

##### 新的衡量指标：响应时间

在我们已知任务执行时间和任务只使用cpu时，唯一的衡量指标就是周转时间。可是现实不会让我们过的这么轻松。由于分时系统的存在，操作系统允许用户一边听音乐，一边坐在中断面前等待终端的输出——这要求系统有很好的交互性。

交互性也就意味着，用户在终端输入命令后，系统应该及时反馈，于是我们引入一个新的衡量指标：*响应时间（response time）*。响应时间被定义为从任务到达系统到首次运行的时间。

$T_{响应时间}=T_{首次运行}-T_{到达时间}$

加入该衡量指标，我们联想之前的调度策略，它们在响应时间上并不是很友好。

于是，我们应该如何构建一个对响应时间敏感的系统？

##### 轮转

为了解决这个问题，我们将介绍一种新的调度算法，通常被称为*轮转（Round-Robin， RR）*调度。基本思想很简单：RR在一个*时间片（time slice，有时被称为调度量子， scheduling quantum）*内运行一个工作，然后切换到运行队列的下一个任务，而不是一直运行一个任务直到结束。

> [!warning]
>
> 请注意，时间片的长度必须是<u>时钟中断周期的倍数</u>。

不再举例说明，时间片越短，在响应时间的表现上会越好，但是，太短的时间片会带来新的问题：突然上下文切换的成本将会影响整体性能。因此系统设计者需要权衡时间片的长度，使其足够长，以便能够*摊销（amortize）*上下文切换成本，而又能保证系统及时响应。

> [!note] 摊销可以减少成功
>
> 当某些系统操作存在固有成本时，通常会使用摊销技术。通过减少成本的频度，也就是减少执行次数，系统对于这些操作的总成本就会降低。例如，时间片设置为10ms，且上下文切换需要1ms，那么需要浪费10%时间用于上下文切换。现在要摊销这个成本，可以把时间片增加到100ms，在这种情况下，仅1%的时间用于上下文切换，因此时间片带来的成本就被摊销了。

提醒一下，上下文切换的成本不仅仅是保存和恢复少量寄存器所造成的。程序运行时，它们在在cpu高速缓存、tlb、分支预测器和其他片上硬件中建立了大量的状态。切换进程会导致这些状态刷新，且新进程也需要更新相关的状态，这可能会导致成本大大增加。

我们当前还是建立在性能指标只有响应时间的基础上的，如果加入周转时间呢，实际上，RR调度在周转时间上表现是非常差的，甚至很多情况下不如FIFO。

更一般的说，任何公平的调度策略（比如RR就是，每个时间片调度一个进程）在周转时间上的表现都不好。这同样也是一种权衡，鱼与熊掌不可兼得，不能既要又要。

总结一下，至此我们已经提出了两种调度策略：

1. 针对周转时间：SJF，STCF，但是对响应时间不利
2. 针对响应时间：RR，但是对周转时间不利

并且我们还有两个假设需要放宽：假设4（作业没有I/O）和假设5（每个作业运行时间是已知的）

> [!tip] 重叠可以提高利用率
>
> 重叠（overlap）操作可以最大限度的提高系统利用率。比如执行磁盘I/O操作时，可以切换进程执行。任何一种情况下，开始操作然后切换到其他工作都是一个好主意，这也提高了系统的整体利用率和效率。

##### 结合I/O

<u>放宽假设4:所有程序都可能执行I/O操作。</u>

正在运行的作业在I/O期间，不会使用CPU，它被阻塞直到I/O完成。这段时间对于CPU而言如果什么都不干是非常浪费的，因此调度程序需要在某个进程发起I/O操作时，及时切换到另一个进程以充分利用cpu，并且在原来进程I/O操作完成后及时切换回去，以保证良好的响应性。操作系统如何处理？也就是说这样的调度策略应该是怎样的？

比如现在有两项工作A和B，每项工作需要50ms的cpu时间，两者区别就是对于A，每隔10ms发起一个IO请求，并且每个I/O都需要10ms，而B只是使用CPU50ms，不执行I/O。调度程序先执行A后执行B。

假设我们正在尝试构建一个STCF调度程序。这样的程序需要如何考虑将A分解成5个10ms子工作，而B仅仅是单个50msCPU需求？显然，仅运行一个工作，而不考虑如何I/O是没有意义的。

一种常见的做法就是将A的每个10ms子任务都认为是一项独立的工作。因此，操作系统启动时，它的选择是调度10ms的A，还是50ms的B。对于STCF是明确的，选择较短的一个，然后开始执行，在这种情况下是A，然后A进入I/O，只剩下B，B开始执行，然后提交A一个新的子任务，它抢占B并运行10ms。这样做也就实现了前文提到的*重叠（overlap）*。一个进程在等待另一个进程的I/O完成时使用CPU，系统利用率也得到了提升。

因此我们可能找到了一种基本的解决方案：通过将每个CPU突发作为一项工作，调度程序确保“交互”进程的正常运行。当这些交互式作业正在执行I/O时，其他CPU密集型作业即将运行 ，从而更好的利用cpu。

##### 无法预知

有了应对I/O的基本方法，我们来到了最后的假设：调度程序知道每个工作的长度。

这太糟糕了！调度程序怎么可能会知道每个工作的长度。现实情况就是：大部分作业的长度操作系统是无法得知的！

因此我们的任务就成了如何建立一种没有这样先验知识的SJF/STCF？或者说，我们如何将已经得到的一些想法与RR调度结合起来，以便响应时间也有个不错的表现？

#### 调度：多级反馈队列

本章介绍一种著名的调度方法——*多级队列反馈（Multi-level Feedback Queue， MLFQ）*

多级反馈队列需要解决前文调度方法无法同时满足的两个问题：

1. 优化周转时间
2. 降低响应时间

正如上述，我们对即将到来的作业没有先验知识，也就是我们无法预测未来。如何解决？

> [!tip] 从历史中学习
>
> 多级反馈队列是利用历史经验预测未来的一个例子，操作系统中还有很多地方才用了这种思路。如果工作存在着某种阶段性的行为，那么就可以预测，这种思路就有的谈。

##### MLFQ：基本规则

与基本调度一样，我们首先介绍一些基本规则，或者说一些很容易理解的规则，加入更加严格的现实条件后，我们再优化（重写）这些规则。

MLFQ中有许多队列，每个队列具有不同的优先级。任何时刻，工作只能存在于一个队列中，操作系统会优先执行优先级更高的队列中的工作，对于处于同一个优先级队列中的工作才用RR调度策略。

关键问题在于如何设置优先级，也就是说我们怎样判断什么样的进程优先级是高的，什么样的进程优先级是短的。MLFQ的思路就是通过观察某个进程的行为，来判断将来的一段时间是否再次被响应，比如如果一个进程发起了一个I/O操作，那么我们认为它将来可能需要再次调用，因此这是一个交互型的进程，需要较短的响应时间，因此我们就把它放在较高的优先级队列；相反，如果一个进程长时间占用cpu，那么MLFQ就降低其优先级。

两个基本规则：

- **规则1**：如果A的优先级>B的优先级，运行A而不运行B。
- **规则**：如果A的优先级=B的优先级，轮转运行

##### 如何改变优先级

我们必须决定，在一个工作生命周期中，MLFQ如何改变优先级。要做到这一点，我们需要回顾上文提到的，需要记住工作的特点：既有运行时间很短、频繁放弃CPU的交互型工作，也有需要很多CPU时间、响应时间不重要的长时间计算密集型工作。因此我们下面定义最基础的优先级调整算法：

- **规则3**：工作进入系统时，放在最高优先级队列中
- **规则4a**：工作用完整个时间片后，降低其优先级（移入下一个队列）
- **规则4b**：如果工作在其时间片内主动释放了CPU，则优先级不变。

这里规则4b主动释放CPU也就意味着这个工作是一个交互型工作，因此应该保持高优先级以保证较低的响应时间。

事实上，以上的规则，在某种情况下是近似SJF的。

###### 假设来了一个长工作A

并且假设该长工作是一个cpu密集型工作，那么根据上述的规则，从最高优先级队列，每运行一个时间片，就会降到低一个级别的队列中，一直降低最低并一直待在那里。

###### 此时来一个短工作B

假设A运行一段时间后，来了一个较短工作B，此时根据规则3，进入系统时优先级最高，于是先执行B，由于B很短，可能还没有降低到最低优先级队列中已经执行完了，因此此种情况下，MLFQ表现为SJF。

###### 又来了一个带有I/O的工作

根据规则4b，只要该工作在一个时间片内主动放弃了cpu，那么优先级不变。

至此，MLFQ看起来运行良好，长工作好像也可以公平的共享cpu，又可以保证短工作和交互型作业很好的响应时间。然而，仔细想想这样的规则有一些非常严重的缺点！

##### 简单的MLFQ存在的问题

1. 长工作饥饿问题

   如果有很多交互型作业或者不断有新的短作业进入系统，长工作就会一直得不到调度，因此会造成饥饿问题

2. 愚弄调度程序

   聪明的用户可能会写出这样的程序：进程在用完一个时间片之前，进行一次无关紧要的I/O，比如访问一个文件。根据我们的规则，此进程会一直占据cpu而不释放，无法保证公平性。

3. 长工作后续也可能会有交互型操作

   一个程序不同时间可能表现不同的行为，如果一个计算密集型工作在某段时间需要进程交互型操作，但是由于根据我们的规则4a，它已经逐渐降低到低优先级队列了，因此也就无法享受系统中其他交互型作业的待遇，响应时间得不到很好的保证。

##### 尝试提升优先级

解决饥饿问题，我们可以周期性的提升所有工作的优先级。一种简单但有效的做法是：每隔一段时间，将所有的工作都扔到最高优先级队列，于是我们添加新的规则：

- **规则5**：经过一段时间S，就将系统中所有的工作重新加入到最高优先级队列。

新规则解决了前文提到的两个问题：首先进程不会被饿死。其次一个cpu密集型工作如果表现为交互型，通过优先级提升，调度程序也会正确的对待它。

添加时间S导致了一个新的问题：S的值要如何设置才能保证长工作既不会饥饿，交互型工作又能得到很好的响应。这种值被著名的系统研究员John Ousterhout称为*巫毒长量（voo-doo-constant）*。

##### 更好的计时方式

只剩下最后一个问题：如何防止程序被愚弄？导致调度程序被愚弄的根源就是规则4a和规则4b，导致只要在时间片内释放cpu，就保留它的优先级。

这里的解决方案，是为MLFQ的每层队列提供更完善的*CPU计时方式（accounting）*。调度程序应该记录一个进程在每一层消耗的总时间，而不是在调度时重新计时，只要进程完成了自己在这一层的时间份额，那么就降低它的优先级，不管是一次用完的还是好几次用完的。因此我们重写规则4a和4b。

- **规则4**：一旦工作完成了其在某一层的时间配额（无论中间主动释放了多少次CPU），就降低其优先级（移入低一级队列）

##### 总结

重新总结优化后的MLFQ规则

1. 如果A的优先级>B的优先级，运行A不运行B
2. 如果A的优先级=B的优先级，轮转运行AB
3. 工作进入系统时，放在最高优先级
4. 一旦工作用完了其在某一层的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级（移入到低一级队列）
5. 经过一段时间S，就将系统中所有工作重新加入到最高优先级队列

#### 调度：比例份额

1. 彩票调度
2. 步长调度

比例份额的目标很直接：保证所有的工作都按照一定比例分到cpu时间。

> [!tip] 关键问题：如何按照比例分配cpu
>
> 如何设计调度程序按照比例分配cpu？关键的机制是什么？效率如何？

##### 彩票数表示份额

彩票调度背后是一个非常基本的概念：彩票数。这也是实现彩票调度的核心机制。彩票数表示的就是某个进程占有cpu时间的比例份额。和这个调度名字一样，工作是否获取cpu取决于运气？看起来是这样的，操作系统通过不断的“抽彩票”，来选择调度不同的进程，crazy！

下面通过一个例子来详细介绍彩票调度的运行过程：假设有两个进程A和B，A拥有75张彩票，B有25张彩票，也就是说我们希望A运行75%的cpu时间，B运行25%的cpu时间。通过不断定时的抽取彩票来决定调度哪一个，抽取过程很容易，调度程序必须要知道所有的彩票数，从0-99随机一个数，如果落在了0-74，调度A，落在了75-99，调度B。

> [!note] 利用随机性通常是一个不错的选择～
>
> 彩票调度的主要优势就是利用了*随机性（randomness）*。当你需要做决定的时候，采用随机的方式通常是既简单又可靠的方式～
>
> 相比于传统的调度策略，随机有三点优势：
>
> 1. 避免奇怪的边界问题
> 2. 实现简单，几乎不需要记录任何状态
> 3. 快。产生随机数快，调度就快。

彩票调度的缺点很明显：短时间内无法保证公平性。运行时间越长，得到的cpu时间比例就越接近期望值。

##### 彩票调度的其他机制

1. 彩票货币的概念：用户可以根据自己的需求重新将自己所占的彩票份额转为自己的货币形式分给自己的工作，之后操作系统再自动将这种货币兑换为对应的全局彩票。
2. 彩票转让：通过转让，一个进程可以临时将自己的彩票交给另一个进程。
3. 彩票膨胀：通过膨胀，一个进程可以临时提升或降低自己所拥有的份额。但是正常竞争环境下，进程之间互相不信任，这种机制也就没有什么价值了。

##### 彩票调度的实现

一个随机数生成器、一个记录所有进程的数据结构（一个列表）、以及所有的彩票总数

假设列表是链表，每个节点记录了进程和所拥有的彩票数，那么我们就可以生成一个随机数，从头开始遍历，记录一个counter值，将每个进程的彩票数加到counter上，只要counter超过了这个随机数，此时当前列表元素所对应的元素就是要调度的目标进程。

当然，如果将链表降序排列，可以更快调度。

##### 如何分配彩票

这是一个非常棘手的问题，系统的运行严重依赖于彩票的分配。假设用户知道自己如何分配，给定他一定量的彩票，由用户自己分配，这似乎什么都没有解决。。。。因此对于给定的一组工作，彩票分配的问题依然没有最佳答案。

##### 如何解决短时间的不确定性

*步长调度（stride scheduling）*，一个确定性的公平分配算法。

只需要稍加改进彩票调度，系统中每个工作都有自己的步长，这个步长与彩票数成反比。我们用一个大数除以每个进程的彩票数得到它们的步长，比如一开始那个例子，A有75张彩票，B有25张彩票，我们用750除以这两个数，得到10和30，这也是A和B的步长。

接下来每次进程运行后，我们就会让它自己的计数器增加一个它自己的步长，记录它的总的长度。

之后，调度程序每次进行调度时，只需要调度总步长最短的那个进程就可以了，并且每次运行一个进程就将它的总长度加上它的步长。

很显然，在一个调度周期内，步长调度是完全公平的，这种结果也是确定的。这相对于彩票调度是它的一个优势。

辩证的看待事物，它没有缺点吗？有的。步长调度需要维护一个全局状态，记录每个进程当前的总的长度。此时如果一个新的进程加入到系统了，我们应该怎么设置它的总长度？设置为0？那么就会导致新的进程一直独占cpu。所以步长调度不是很好处理新加入系统的进程。

##### 小结

比例份额不是通用的调度程序。两个原因：

1. 不太适合I/O
2. 票数分配无法解决

比例份额调度只适合与一些特定的场景，比如虚拟机，我们可能只想cpu的1/4用来运行虚拟机，此时比例份额的调度就派上用场了。

#### 多处理器调度

我们之前讨论的调度程序都是在单处理器上的调度，随着时代进步多处理架构的机器早已普及，因此首先要想到的问题我想应该是如何把单处理调度的思路移植到多处理器调度上？我们又会在这个过程遇到什么样的问题？如果不能直接移植，需要做出哪些改进或者重新设计怎样的策略？

##### 背景：多处理器架构

要搞清楚多处理器调度带来的问题，首先要知道它与单cpu之间的区别。主要区别在于对硬件缓存的使用，以及多处理之间的数据共享的方式。

我们知道，单cpu系统中存在多级的硬件缓存，可以让处理器有更少的空闲时间，利用率更高。缓存是一个很小但是很快的存储设备，通常拥有内存中最常使用的数据的备份。通过将频繁访问的数据放在缓存中，让系统看起来好像拥有又快又大的内存空间。

缓存基于*局部性（locality）*的概念，局部性分为时间局部性和空间局部性。

> [!note]
>
> 时间局部性：当一个数据被访问后，它很可能会在不久的将来再次被访问。
>
> 空间局部性：当程序访问地址为x的数据时，很可能会紧接着访问x周围的数据

由于这两种局部性的存在，硬件系统可以很好的预测哪些数据可以被放入缓存，从而得到很好的表现。

但是如果放到多处理器中，各个处理器共享一个内存，每个cpu独享自己的缓存，这里就有一个*缓存一致性*的问题，比如CPUA某个程序从内存中得到数据后并修改，为了效率，它选择不立即写回内存而是稍后进行，此时操作系统中断了该程序的运行，而是把它交给了CPUB来运行，由于CPUB中没有该数据的缓存，于是从内存读取，但是读到的却是以前的数据！

硬件提供了这个问题的基本解决方案：通过监控内存访问来保证数据正确性。在基于总线的系统中，一种方式是使用总线窥探，每个缓存通过监听链接所有缓存和内存的总线，来监听内存访问。如果cpu发现对它放在缓存中的数据已经在内存中更新，就会作废缓存中的副本，或者选择更新它，具体取决于协议的不同。

比较常见的协议是*MESI*协议。

##### 同步问题

即使硬件已经给我做了很多关于一致性的保证，但是应用程序仍然要注意共享数据带来的问题。比如跨CPU访问共享数据时，需要使用互斥原语，才能保证正确性。随之带来的就是性能问题，尤其在cpu数量变多时这个问题会更加明显。

##### 缓存亲和度

*缓存亲和度（cache affinity）*：一个进程在某个CPU上运行时，会在该CPU的缓存中维护许多状态。下次该进程在相同CPU运行时，由于缓存中的数据仍然在，因此运行会更快；相反，在不同CPU上执行，会由于需要重新加载数据而变慢。

因此多处理器调度应该考虑到这种缓存亲和度，尽可能保证一个进程在同一个CPU上运行。

##### 单调队列调度

最基本又简单的方式，就是将单处理器调度直接移植到多处理器调度中，将所有要运行的工作放在一个队列中，我们称这种调度方式为*单队列多处理器调度（Single Queue Multi processor Scheduling，SQMS）*。

最大的优点就是实现简单，当然缺点也很明显：

1. 缺乏可扩展性。需要加锁才能保证原子性。加锁带来的就是性能损失。
2. 缓存亲和度很差。因为单队列没有考虑进程是否在同一个CPU运行，导致某个工作可能会在不同的CPU之间来回切换，缓存亲和性很差

##### 多队列调度

由于单队列调度缺点太过明显，性能也不高，因此有些系统采用了多队列的方案，每个CPU一个队列，称这种调度为*多队列多处理调度（Multi-Queue Multiprocessor Scheduling, MQMS）*。

每个CPU独享一个队列，每个队列的调度算法可以是之前的单处理器调度的任何一个，当工作第一次进入系统时，根据某种启发式规则，将工作加入到某个CPU的队列。

多队列保证了多个CPU之间的队列相互独立，从而减少了同步带来的性能损失以及提升了缓存亲和度。

但是辩证的看待，又有了新的问题：负载不均衡。这几乎是所有多核心系统都要考虑的一个问题。

解决这个问题，我们可以考虑允许工作从一个CPU移动到另一个CPU，这是很容易能想到的。但是伴随而来的新问题就是：系统如何决定什么时候发起工作的移动。

一个基本的方法就是采用*工作窃取（work stealing）*的技术。通过这种方法，工作量较少的队列不定期的“偷看”其他队列是不是工作量比自己多，如果目标队列比自己的队列中工作更多，就从目标队列“窃取”一个或多个工作，从而实现负载均衡。

当然，这种方法也有自己的弊端，如果太频繁的监听其他队列也会导致性能损失，而且可扩展性也不是很好。这种阈值仍然是一种难以把控的量……

#### 总结

至此，我们介绍完了CPU虚拟化的部分，可以看到，总的来说CPU虚拟化就是操作系统不断的切换CPU控制权给不同的进程，每个进程看起来好像都是在独享CPU的，只要它每次执行的时间是可以接受的，它就察觉不到这个CPU并不是它独享的悲剧。

回顾操作系统的设计目标：

建立一个抽象，使得应用程序使用更加方便；提供一个高性能的系统；不同进程之间以及进程与OS之间提供隔离（保护）

虚拟化CPU的过程完全就是契合这个目标的过程，闭上眼睛，考虑一下虚拟化CPU哪些方面实现了操作系统的设计目标……如果你说不出来，那就再仔细看看吧！

- 所谓的抽象就是进程，所有运行的程序都被抽象为了一个进程，所谓的方便程序使用实际上也是方便系统控制的一种表述，表面上我们在控制计算机，实际上是操作系统在控制！
- 我们一直在保证虚拟化CPU的前提上追求高性能。。。
-  受限直接执行。。。这很容易想到

### 虚拟化内存

用户程序生成的每一个地址都是*虚拟地址*，操作系统骗了所有的进程！它让所有进程都以为自己独占一个庞大而连续的*地址空间*，在硬件的帮助下，将这些虚拟地址映射到了实际的物理地址，而每个进程还在为自己独占庞大的地址空间而沾沾自喜呢……

除此之外，操作系统还得保证不同进程之间不能相互访问和覆写彼此的进程空间，这也是所谓的*保护*和*隔离*，不要急～接下来会慢慢介绍的～

与虚拟化CPU类似，我们将会从最简单的概念入手，让你读起来会发出这样的感叹：操作系统的设计怎么会这么简单！

大道至简……

#### 抽象：地址空间

与进程很像是不是！

早期操作系统就是一组函数，所用的内存也是实实在在的物理内存，那时几乎没有抽象，但是随着内存空间变大以及用户对操作系统的要求也越来越高，这种简单的内存管理已经无法满足要求……

再到后来多道程序系统时代开启，多个进程都想占用cpu，于是有了时分共享。一种时分共享的方法，就是让一个进程单独占用全部内存运行一小段时间，然后停止它，并将它的所有状态保存到磁盘中，再加载其他进程的信息以切换进程，再运行一段另一个进程，这就是一种早期比较粗糙的机器共享。

这个方法有个非常明显的短板：效率太低。我们后面在持久化中会清晰的感受到，每多一次I/O操作带来的成本是无法想象的。

于是，用户再次增加需求，伟大的计算机先驱们开始设计让每个进程都拥有一段物理内存，但这时*保护（protection）*就成了主要的问题，如何保证每个进程的内存是独享而不被其他进程所打扰（读/写）？

##### 地址空间

为了解决这种看起来烦人的需求，我们设计了在内存中最基础的抽象：*地址空间（address space）*，所谓地址空间，就是运行的进程所看到的系统的内存。进程看到的内存以为就是实际的物理内存，但实际不是，操作系统为我们做了关于内存地址的透明。

地址空间是关于虚拟化内存最重要的抽象，因此需要好好理解。

一个进程的地址空间包含了进程的所有状态。比如代码、栈、堆、静态变量等。为了简化，我们假设只有代码、栈和堆三个部分。

比较常见的一种内存布局：

![image-20241005191154311](https://gitee.com/raining976/markdown-imgs/raw/master/img/image-20241005191154311.png)

地址空间开始存储的是程序的代码部分，然后是堆，栈是从地址空间最大值开始反向增长的。事实上这样的内存布局只是一种约定，当我们在并发部分了解到多线程时，事情就没有那么容易了。

重申一下这个问题，当我们描述进程的地址空间时，所描述的是操作系统提供给进程的一种抽象，实际的物理内存并不在0-16KB处，而是加载在任意的物理内存中（操作系统与硬件协调）。

因此我们能够想象到，虚拟化内存的关键是：如何确保每个进程的地址（私有地址空间的地址）可以正确映射到对应的物理地址。

解决了这个问题，那么虚拟化内存也就实现了～

##### 虚拟内存系统的目标

1. 透明。

   操作系统实现了虚拟内存，对于进程应该是不可见的，也就是说进程认为自己使用的就是物理内存，或者说使用私有内存地址和使用物理内存无异。

2. 效率。

   高效也是操作系统的设计目标之一，因此可以说任何一个子系统的目标都包含了高效。虚拟化内存本质上是建立私有地址空间与物理内存的映射关系，如何保证高效，时间上要快速，空间上也不能占用太多的物理内存空间。我们在之后会接受一个非常重要的硬件TLB，可以说这是虚拟化内存高效的关键。

3. 保护。

   这也是操作系统设计目标之一，我们不希望任何进程被其他进程所影响，包括其所拥有的内存。

接下来，我们将介绍虚拟化内存的基本机制，以及相关策略。

还是同样的，机制告诉我们如何实现，策略告诉我们做什么

#### 机制：地址转换

回顾一下，在虚拟CPU时，我们采用的关键机制是受限直接访问LDE，LDE的基本思想是：让程序运行的大部分指令直接访问硬件，只在一些关键时候，由操作系统介入执行。为了实现高效的虚拟化，操作系统应该让程序自己运行，同时在关键的时候介入，确保其掌控性。

高效和控制也是现代操作系统的两个主要目标。

我们在实现虚拟化内存时也要追求类似的策略。高效决定着我们要依赖硬件的支持，控制意味着操作系统要确保进程只能访问自己的内存空间。额外的一点要求：灵活，我们希望进程可以用任意的方式访问它自己的地址空间，从而让系统更容易编程。

> [!important] 关键问题
>
> 高效、灵活、保持控制

我们采用了一种通用技术：*基于硬件的地址转换（hard-based address translation）*，简称为*地址转换（address translation)*。它可以看成受限直接执行的这种一般方法的补充。

利用地址转换，硬件每次对访问的地址进行处理（指令获取、数据读取或写入），将指令中的虚拟地址转为实际的物理地址。可以看出来，每次进程访问内存都会发生地址转换，将进程的内存饮用重定向到实际的物理内存位置。

硬件实现了虚拟内存的基本机制，而操作系统做的事情就是*管理*，记录被占用和空闲的内存位置，并谨慎介入，保持对进程的控制，也就是限制进程对已被占用的内存的访问等。

##### 最简单的假设

地址空间必须连续的放入内存，并且假设地址空间小于实际的物理内存（实际的虚拟化地址空间可以大于物理内存，很神奇吧～）

同样的思路，接下来的介绍将会慢慢放宽这种假设，直到它接近现实情况。

##### 基于硬件的动态重定位

基址+界限的思想，就是记录该进程地址空间开始位置对应的物理地址，再记录一个进程地址空间的大小，界限主要是为了控制进程不要访问到其他位置。

具体来说，CPU需要两个硬件寄存器，*基址（base）*寄存器和*界限（bound）*寄存器，这两个寄存器就可以让我们将进程的地址空间放在物理内存的任何地方，同时又确保进程只能访问自己的地址空间。

> [!note] 基于软件的静态重定位
>
> 有一个加载程序的软件，在程序运行前先把地址重写到物理内存中期望的偏移位置。
>
> 比如：程序有一条指令从1000加载到寄存器，当整个程序地址空间被加载到从3000开始的物理内存中，加载程序会重写指令中的地址，也就是将1000改为1000+3000=4000。完成简单的重定位
>
> 缺点很明显：不提供保护；一旦完成重定位，后续很难再重定位其他位置了。

硬件实现的地址转换是在程序运行的时候发生的，因此我们称这种技术为动态重定位。

这种基址寄存器配合界限寄存器每个CPU都有一对，有的时候我们称这个负责地址转换的部分统称为*内存管理单元（Memory Management Unit，MMU）*。

检查界限的时机有两个：

1. 硬件在将虚拟地址与基址寄存器值求和之前
2. 求和转为物理地址之后

##### 操作系统做什么事

1. 进程创建时，操作系统要为进程的地址空间找到对应的内存空间。由于我们的假设是每个进程的地址空间都一样，并且小于物理内存大小，因此这很容易实现。比如可以把整个物理内存看作一个空闲块，每当需要分配空间给进程时就找到一个对应的块大小分给它，然后切分剩余部分等着其他进程使用。这个过程也可能产生一些不连续的空闲内存块，最简单的方式就是维护一个空闲链表。
2. 进程终止时，操作系统需要回收这部分内存空间，具体就是将该部分空间放进空闲链表，顺便进行一些连续空闲内存的碎片的合并操作等等。
3. 上下文切换时，操作系统要进行一些额外的操作。比如将当时基址和界限寄存器的值存储到一个每个进程都有的数据结构中，我们有时称这个数据结构叫*进程控制块（Process Control Block，PCB）*，名称不重要，这只是一个名字。
4. 操作系统还要提供异常处理程序。比如进程越界访问了，需要触发异常，陷入操作系统，执行对应的异常的处理程序，杀死进程或者做别的事情。

##### 辩证分析

我们这一章节介绍了基于硬件的动态重定位技术，但是可以容易的发现，固定每个内存地址空间大小，然后将整个进程的地址空间都映射到物理空间有个很严重的问题：进程地址空间很多空间都是空闲的，也就是不是所有的进程都会完全使用满自己的进程空间，因此就出现了内存空间的浪费，我们称这样的浪费为*内部碎片（internal fragment）*，所谓内部其实指的就是进程内部，将来我们还会了解什么是外部碎片，慢慢来吧～

为了解决这种内部碎片，比较简单的解决方案就是将基址和界限的概念泛化，得到*分段（segmentation）*的概念。

所谓的泛化实际上就是：本来基址和界限指的是一个进程的，现在我们可以将整个概念提取出来，一个进程的某些部分也可以有基址和界限了。就是将这个概念一般化，不是只有进程享有了，可能进程的一个部分也可以享有。

#### 分段

以前我们虚拟化内存是将进程的整个地址空间完整映射给物理内存，但是这样的结果就是堆和栈之间有很大的空闲空间，而这些空间我们甚至也不确定进程是否使用，因此优化这部分空间是必须要做的事情。

加上我们最初的假设仅仅是很小的地址空间， 一旦地址空间很大，甚至超过物理内存了，我们不可能每次都将进程的地址空间完整的映射给物理内存，这样其他进程就没有内存可用了～～

##### 分段：泛化的基址/界限

分段很容易：MMU引入不止一对基址/界限寄存器，而是给地址空间的每个逻辑段一对，分别标注代码、堆和栈。

像下图这样：

![image-20241005200709201](https://gitee.com/raining976/markdown-imgs/raw/master/img/image-20241005200709201.png)

##### 如何知道引用的是哪个段

硬件在地址转换的时候如何知道当前段是哪个段从而使用不同的寄存器值进行转换？

常见的一种方式是*显式方式*，在虚拟地址的开头几位标注不同的段，比如三种段可以用两位标注。

两位标注三个段可能会造成浪费，有的系统可能会将堆和栈当成一个段，此时就可以用一位标识了。

也有*隐式方式*，通过地址产生的方式来确定，比如由PC产生的就是在代码段，基于栈或者基址指针的就是在栈段，其余的在堆段。

##### 如何处理栈？

栈是反向增长的，因此我们需要单独处理栈的地址转换。

实际操作就是：偏移量减去最大段地址，然后加上基址就得到了正确的物理地址。

##### 如何共享

为了节省内存，有时候需要共享某一部分内存，尤其是代码部分的共享，现在的系统也会用。

为了支持共享，仍然需要额外的硬件支持，通过加入*保护位*实现。为每个段增加几个位，标识程序能否读写或者执行其中的代码。通过将代码段标识为只读，这样同样的物理内存可以被多个进程共享，而不用担心破环隔离（因为是只读的），但在进程看来自己还是独享这部分空间的！这就是虚拟化的魅力！

##### 操作系统应该做什么

1. 各个段的基址/界限寄存器值需要被保存或恢复。

2. 管理物理内存的空闲空间。

   我们之前假设所有的地址大小空间都一样大，物理空间是一些槽块，进程可以放进去，现在加入了分段的概念，每个进程有一些段，不同段大小不同，这样随着各种进程的运行，实际物理内存会出现各种各样的小的连续物理内存空间，从而导致很难分配给新的段（连续分配的假设）这样的问题被称为*外部碎片（external fragmentation）*，如下图：

   ![image-20241005201911297](https://gitee.com/raining976/markdown-imgs/raw/master/img/image-20241005201911297.png)

   两种解决方案：

   - 紧凑物理内存。通过对应的程序，定期将物理空间拷贝移动到更紧凑的布局。但是显然效率低，成本大。
   - 空闲列表管理：试图保留大的内存用于分配，这其中涉及到很多管理算法，包括最优匹配，第一次匹配等

##### 小结

分段解决了内部碎片（不完全解决）的问题，而且容易实现，地址转换的开销仍然很小（基于硬件）。还有个附加优势：支持代码共享，代码放入独立的段中，多个进程可以共享。

新的问题：外部碎片，更重要的一个问题是不足以支持更一般化的稀疏空间。比如，有一个很大但是很稀疏的堆，采用分段我们仍然需要分配很大的物理空间，仍然存在内部碎片，也就是我们并没有完全解决内部碎片的问题，换句话说现在的内存虚拟化思路并不是具有普适性，这远远没有达到我们的目标，因此我们还需要新的解决方案。

#### 插叙：空闲空间管理

空闲链表管理相关的内容

#### 分页

分段存在一个无法解决的问题：会导致外部碎片，整个堆空间慢慢被切割成各种各样的小块，后续的空间分配会非常麻烦。

为了解决这种问题，我们使用分页：将空间按照固定大小先切割成页，对应物理内存也按照页大小分割成固定的槽块，每个槽块叫页帧。

现在的问题是：如何利用页实现虚拟内存，同时还要避免分段带来的问题？

为了标记进程中某一个虚拟页映射到哪个物理页，进程还需要一个特殊的数据结构：页表，页表用来存储每个虚拟地址到物理地址的转换，从而可以很容易找到虚拟地址的物理地址。

注意这个页表也是存储在内存中的，也就是说如果我们要访问一个虚拟地址，要先访问一遍页表，从页表找到目标地址，这个过程多了一遍访存。

有了分页的设计，虚拟内存的每位表示的信息也要重新设计，一般是高几位表示虚拟页号，剩余低位表示页内偏移，对于物理页帧和虚拟内存大小是固定的，因此虚拟地址到物理地址的转换就仅仅是虚拟页号和物理页帧的转换。

##### 页表的存储问题

页表一般存在内存中，但是随着计算机技术的进步，32位的机器甚至64位机器的普遍，一个进程的页表可能会变得非常大。比如32位的地址空间，每个页4kb大小，虚拟地址要分成高20位存页号，低12位存页内偏移。假设一个页表项需要4字节，那么页表一共所占的内存高达4MB！这非常大！这仅仅是一个进程的页表的所占的内存，想象一个机器中假设100个进程在运行（往小了说），一共需要400MB内存！这仅仅为了做虚拟内存的转换。

因此页面占用如此多的内存也不是我们所期待的，在以后的章节会慢慢降低这种占用，现在你只需知道：页表可能占用很大的内存！

##### 页表中究竟存什么？

首先页表是一种数据结构，简单的形式是一个数组，通过虚拟页号检索该数组，然后在该索引处的页表项找到期望的物理页帧号。

至于每一个PTE（Page Table Entry），其中有许多有用的项值得我们了解。

- 有效位：指示该地址转换是否有效
- 保护位：标记该页是否可以读取、写入或执行
- 存在位：表示该页是在物理存储器还是磁盘上
- 脏位：表示该页被载入内存后是否被修改过
- 参考位：用户追踪页是否被访问，页面替换中非常重要，后面会介绍

##### 分页效率也不高

由于内存中的页表很大，也会导致分页设计的内存访问很慢。

另一个问题：页表存储在内存中，我们如何知道页表位置？

很简单！依赖一个硬件，加一个寄存器，专门放这个进程的页表到物理页帧的转换就可以了。

接下来的工作就是得到访问内存中的页表，找到我们想要访问的内存页表条目，然后访问目标物理内存！

这个过程一共需要两次访问，1访问页表，2访问目标指令（数据或其他）所处的物理内存

这种额外的内存访问会严重拖垮我们的访问时间，如果不仔细设计硬件和软件的配合，页表会导致系统运行很慢。

#### 快速地址转换（TLB）

加入硬件配合后的地址转换。

硬件管理的TLB通常不需要我们了解过多细节，只需要知道硬件会帮我们缓存一部分地址转换，这样我们在访问内存时就不需要额外访问一遍页表了，而是直接使用tlb中的缓存。少了一次访存，对于缓存的访问消耗一般是极小的，所以性能理论上会有很大提升。

硬件管理的TLB的算法如下：

1. 首先从虚拟地址取页号（VPN），然后检查TLB中是否有该VPN的地址转换，如果有，TLB命中，那就直接取出对应的物理页帧号，访存即可。
2. 否则，TLB不命中，此时我们需要访问页表，<u>然后更新TLB，然后再次执行这次命令</u>，此时TLB显然一定命中，然后进行访存。

可以看出来，TLB不命中时仍然会有一次额外的访存，但是平均上效率一定有所提升。

依托TLB的访存设计思路，我们提升的目标应该是尽可能降低TLB未命中次数。

##### 举个例子：访问数组

![image-20241017183718009](https://gitee.com/raining976/markdown-imgs/raw/master/img/image-20241017183718009.png)

数组位于地址空间的布局如上，现在我们考虑一个这样的过程：

```c
int sum = 0;
for (int i = 0; i < 10; i++){
  sum += a[i];
}
```

简单期间，我们认为这个循环产生的内存访问仅只针对数组（忽略i和sum变量以及指令本身，只有对于数组a的访问）。当访问第一个元素的时候，数组第一次被访问，TLB一定未命中，但是TLB一次性加载一整页的页表，第二个、第三个元素都在同一页，因此在第一次未命中时就已经从内存中加载到TLB中，因此第二第三次访问都是命中的，后面的也是同理`a[3]`未命中，`a[4],a[5],a[6]`命中，`a[7]`未命中，`a[8],a[9]`命中。

这也是由于空间局部性，机器在这样设定时，就认为如果你访问了一元素，那么短时间内机器会认为我们还会访问这个元素物理内存中周围的内容，这就是空间局部性。

顺便说一句，TLB本身也利用了时间局部性的原理，载入的TLB的页表，都是最近访问的，系统认为用户短时间内还会访问这些元素。

##### 谁来处理缓存未命中？

一般分为硬件和软件。用程序语言的思想理解这个过程，如果TLB未命中，那么

## 持久性